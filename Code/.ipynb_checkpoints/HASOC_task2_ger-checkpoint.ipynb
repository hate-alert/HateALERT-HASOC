{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:03:57.269045Z",
     "start_time": "2019-08-07T07:03:56.063866Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:03:58.015649Z",
     "start_time": "2019-08-07T07:03:57.992168Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:03:58.690766Z",
     "start_time": "2019-08-07T07:03:58.678923Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:03:59.875313Z",
     "start_time": "2019-08-07T07:03:59.365551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:04:17.263591Z",
     "start_time": "2019-08-07T07:04:17.217849Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset.tsv', sep='\\t')\n",
    "# #hindi_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t',header=None)\n",
    "# german_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset_added_features.tsv', sep=',')\n",
    "# eng_train_dataset=eng_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "# german_train_dataset=german_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.loc[eng_train_dataset['task_1'] == 'HOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:05:29.488930Z",
     "start_time": "2019-08-07T07:05:29.462173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>hasoc_de_39</td>\n",
       "      <td>ðŸ’©ðŸ‘‰'Cohn-Bendit ist kein altersverwirrter Spinn...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>hasoc_de_67</td>\n",
       "      <td>@ArasBacho Wer hat dem kriminellen Grapscher d...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>hasoc_de_83</td>\n",
       "      <td>Alfred Nobel wÃ¼rde sich im Grab rumdrehen.  Ei...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>hasoc_de_97</td>\n",
       "      <td>Das SchÃ¶ne am Klimawandel: Damit lÃ¤sst sich vo...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hasoc_de_99</td>\n",
       "      <td>@lawyerberlin @Lebensformation ich nenne jeden...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                               text task_1  \\\n",
       "38  hasoc_de_39  ðŸ’©ðŸ‘‰'Cohn-Bendit ist kein altersverwirrter Spinn...    HOF   \n",
       "66  hasoc_de_67  @ArasBacho Wer hat dem kriminellen Grapscher d...    HOF   \n",
       "82  hasoc_de_83  Alfred Nobel wÃ¼rde sich im Grab rumdrehen.  Ei...    HOF   \n",
       "96  hasoc_de_97  Das SchÃ¶ne am Klimawandel: Damit lÃ¤sst sich vo...    HOF   \n",
       "98  hasoc_de_99  @lawyerberlin @Lebensformation ich nenne jeden...    HOF   \n",
       "\n",
       "   task_2  \n",
       "38   OFFN  \n",
       "66   OFFN  \n",
       "82   OFFN  \n",
       "96   OFFN  \n",
       "98   OFFN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:05:45.910175Z",
     "start_time": "2019-08-07T07:05:45.900972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFFN    210\n",
      "HATE    111\n",
      "PRFN     86\n",
      "Name: task_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_2'].value_counts()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:06:36.488028Z",
     "start_time": "2019-08-07T07:06:36.467355Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/german_dataset/embeddings_ger_task23_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/german_dataset/embeddings_ger_task23_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/german_dataset/no_preprocess_bert_embed_task23.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:06:37.374147Z",
     "start_time": "2019-08-07T07:06:37.368837Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'HATE':0,\n",
    "    'PRFN':1,\n",
    "    'OFFN':2\n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    0:'HATE',\n",
    "    1:'PRFN',\n",
    "    2:'OFFN'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:06:44.330755Z",
     "start_time": "2019-08-07T07:06:44.301818Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_2'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:06:45.134743Z",
     "start_time": "2019-08-07T07:06:45.031835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 407/407 [00:00<00:00, 4639.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:07:10.671375Z",
     "start_time": "2019-08-07T07:07:10.517639Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:07:12.611685Z",
     "start_time": "2019-08-07T07:07:12.588616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 0., 2., 2., 2., 2., 2., 2., 2., 0., 0., 0., 0.,\n",
       "       2., 0., 2., 0., 0., 0., 0., 0., 1., 1., 2., 2., 0., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 1., 1., 2., 2., 1., 2., 2., 1., 2., 2., 2., 1., 1.,\n",
       "       0., 2., 1., 1., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 0.,\n",
       "       2., 2., 2., 2., 2., 0., 1., 2., 2., 2., 2., 0., 2., 2., 2., 2., 0.,\n",
       "       2., 2., 1., 2., 2., 1., 2., 0., 2., 2., 2., 2., 2., 2., 2., 1., 1.,\n",
       "       0., 0., 2., 2., 2., 2., 2., 2., 0., 2., 2., 2., 2., 0., 0., 0., 1.,\n",
       "       2., 2., 2., 1., 2., 1., 1., 2., 2., 2., 1., 2., 1., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 1., 1., 2., 2., 2., 2., 2., 2., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 2., 1., 2., 1., 1., 1., 1., 1., 2., 2., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 1.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2.,\n",
       "       1., 1., 2., 1., 2., 2., 2., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 0., 2., 1., 0., 0.,\n",
       "       0., 0., 1., 2., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       2., 2., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 2., 2., 1., 2., 2., 1., 2., 1., 2., 2., 2., 0.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 1., 1., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 0., 2., 2., 0., 2., 2.,\n",
       "       2., 2., 0., 2., 0., 2., 2., 2., 2., 0., 1., 1., 2., 1., 2., 2., 2.,\n",
       "       1., 2., 2., 0., 1., 1., 1., 2., 0., 2., 0., 1., 1., 2., 1., 1., 2.,\n",
       "       0., 2., 0., 0., 1., 1., 0., 2., 2., 0., 1., 0., 0., 2., 0., 2., 2.,\n",
       "       2., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:07:13.805888Z",
     "start_time": "2019-08-07T07:07:13.644375Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:37:31.395738Z",
     "start_time": "2019-08-07T07:37:31.370805Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_eng_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['HATE','PRFN','OFFN'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('ger_task2_'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('ger_task2_'+model_type+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T09:05:52.139258Z",
     "start_time": "2019-08-07T09:05:52.115727Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3,class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True)\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,\n",
    "            l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,loss_function='MultiClass')\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='multi:softmax',num_class=3,\n",
    "                             reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='multiclass',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,\n",
    "                                boosting_type='gbdt', metric='multi_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T09:05:16.561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2906976744186047\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 2. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 0. 1. 0. 1. 0. 2. 0.\n",
      " 0. 0. 0. 2. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 2. 0. 1. 0. 1.\n",
      " 0. 0. 0. 2. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 2. 2. 0. 1. 1. 2. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 2. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 2. 0. 0. 1. 2. 1. 1.\n",
      " 1. 1. 2. 1. 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.\n",
      " 2. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1.\n",
      " 2. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 0. 1. 1. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.4547945205479452 accuracy_test: 0.4523809523809524\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.92      0.51        99\n",
      "         1.0       0.67      0.75      0.71        77\n",
      "         2.0       0.89      0.09      0.16       189\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       365\n",
      "   macro avg       0.64      0.59      0.46       365\n",
      "weighted avg       0.70      0.45      0.37       365\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      1.00      0.55        12\n",
      "         1.0       0.67      0.67      0.67         9\n",
      "         2.0       1.00      0.05      0.09        21\n",
      "\n",
      "   micro avg       0.45      0.45      0.45        42\n",
      "   macro avg       0.68      0.57      0.43        42\n",
      "weighted avg       0.75      0.45      0.34        42\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. 0. 1. 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 1. 2. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 1. 1. 0. 2. 0. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 2. 0. 1. 0. 1. 0. 2. 0.\n",
      " 1. 0. 2. 2. 1. 1. 1. 2. 2. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1.\n",
      " 1. 0. 1. 2. 1. 0. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 0. 0.\n",
      " 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 2. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 2. 0. 1. 1. 0. 2. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 1. 1. 1. 1. 1. 0. 1. 2. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 2. 0. 0. 0. 1. 2. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 2.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1.\n",
      " 1. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 1. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 1. 1.\n",
      " 2. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.4918032786885246 accuracy_test: 0.34146341463414637\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.82      0.51       100\n",
      "         1.0       0.63      0.87      0.73        77\n",
      "         2.0       0.78      0.16      0.27       189\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       366\n",
      "   macro avg       0.59      0.62      0.50       366\n",
      "weighted avg       0.63      0.49      0.43       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.73      0.46        11\n",
      "         1.0       0.27      0.33      0.30         9\n",
      "         2.0       0.50      0.14      0.22        21\n",
      "\n",
      "   micro avg       0.34      0.34      0.34        41\n",
      "   macro avg       0.37      0.40      0.33        41\n",
      "weighted avg       0.41      0.34      0.30        41\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 2. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 2. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 2. 1. 1. 1.\n",
      " 1. 0. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 2. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 0. 2. 2. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 1. 2. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 2. 0. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.43989071038251365 accuracy_test: 0.2926829268292683\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.86      0.53       100\n",
      "         1.0       0.52      0.88      0.65        77\n",
      "         2.0       1.00      0.04      0.07       189\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       366\n",
      "   macro avg       0.63      0.59      0.42       366\n",
      "weighted avg       0.73      0.44      0.32       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.73      0.47        11\n",
      "         1.0       0.22      0.44      0.30         9\n",
      "         2.0       0.00      0.00      0.00        21\n",
      "\n",
      "   micro avg       0.29      0.29      0.29        41\n",
      "   macro avg       0.19      0.39      0.26        41\n",
      "weighted avg       0.14      0.29      0.19        41\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 1. 1. 0. 0.\n",
      " 2. 1. 0. 0. 0. 0. 1. 1. 2. 2. 0. 1. 0. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 2. 0. 2.\n",
      " 0. 2. 2. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 2.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 0. 2. 0. 1. 1. 2. 1.\n",
      " 1. 2. 0. 2. 0. 0. 1. 1. 0. 0. 1. 0. 0. 2. 0. 2. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.453551912568306 accuracy_test: 0.36585365853658536\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.94      0.52       100\n",
      "         1.0       0.66      0.73      0.69        77\n",
      "         2.0       1.00      0.08      0.16       189\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       366\n",
      "   macro avg       0.67      0.58      0.45       366\n",
      "weighted avg       0.75      0.45      0.37       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      1.00      0.49        11\n",
      "         1.0       0.67      0.44      0.53         9\n",
      "         2.0       0.00      0.00      0.00        21\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        41\n",
      "   macro avg       0.33      0.48      0.34        41\n",
      "weighted avg       0.23      0.37      0.25        41\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 2. 2. 0. 0. 1. 1. 0. 0. 2. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 2. 0. 1. 1. 0. 1. 1. 1. 0. 0. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 2. 0. 1. 2. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 2. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 2. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 2. 1. 0. 1. 2. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 2. 1. 0. 1. 0. 1. 0. 1. 0. 0. 2. 0. 0. 0. 1. 1.\n",
      " 1. 1. 2. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 2. 0. 2. 1. 1. 0. 0. 0. 2. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 2.\n",
      " 0. 1. 0. 0. 2. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 0. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1.\n",
      " 0. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2. 1.\n",
      " 1. 2. 0. 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.4726775956284153 accuracy_test: 0.2682926829268293\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.86      0.53       100\n",
      "         1.0       0.57      0.84      0.68        77\n",
      "         2.0       0.85      0.12      0.20       189\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       366\n",
      "   macro avg       0.60      0.61      0.47       366\n",
      "weighted avg       0.66      0.47      0.39       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.73      0.43        11\n",
      "         1.0       0.14      0.22      0.17         9\n",
      "         2.0       1.00      0.05      0.09        21\n",
      "\n",
      "   micro avg       0.27      0.27      0.27        41\n",
      "   macro avg       0.48      0.33      0.23        41\n",
      "weighted avg       0.63      0.27      0.20        41\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 2.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 2. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1. 1. 0. 2. 2. 1. 0. 1. 0. 0.\n",
      " 0. 2. 0. 2. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 2. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 2. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 2.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0. 0. 1. 2. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 1. 1. 2.\n",
      " 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2. 0.\n",
      " 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.4562841530054645 accuracy_test: 0.3902439024390244\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.88      0.51       100\n",
      "         1.0       0.59      0.83      0.69        77\n",
      "         2.0       0.94      0.08      0.15       189\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       366\n",
      "   macro avg       0.63      0.60      0.45       366\n",
      "weighted avg       0.71      0.46      0.36       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.82      0.51        11\n",
      "         1.0       0.33      0.44      0.38         9\n",
      "         2.0       0.60      0.14      0.23        21\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        41\n",
      "   macro avg       0.44      0.47      0.38        41\n",
      "weighted avg       0.48      0.39      0.34        41\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 0. 0. 2. 2. 1. 2. 2. 2. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 2. 2. 0. 1. 0. 2. 0. 0. 0. 2. 0. 1. 1. 2. 2. 0. 2. 0. 1. 2. 2. 2.\n",
      " 1. 1. 0. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 0. 2. 2. 0. 1. 2. 2. 0. 0. 0. 2.\n",
      " 0. 0. 2. 0. 2. 1. 0. 2. 2. 1. 2. 1. 2. 1. 0. 0. 2. 2. 2. 2. 2. 1. 1. 0.\n",
      " 0. 1. 2. 2. 1. 2. 1. 0. 2. 0. 0. 0. 1. 0. 2. 0. 1. 2. 0. 2. 2. 0. 1. 1.\n",
      " 2. 2. 0. 1. 0. 1. 1. 0. 1. 1. 2. 0. 0. 1. 1. 1. 1. 2. 0. 1. 1. 2. 1. 2.\n",
      " 1. 1. 2. 2. 1. 1. 0. 1. 2. 1. 0. 1. 1. 2. 2. 2. 2. 0. 2. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 2. 0. 0. 2. 2. 0. 2. 1. 2. 1. 2. 0. 2. 1. 0. 1. 2. 2. 2. 0. 2.\n",
      " 0. 0. 0. 2. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0. 1. 0. 2. 2. 0. 0. 2. 1. 0. 0.\n",
      " 2. 2. 2. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 0. 0. 2. 0. 0. 0. 0. 2. 0.\n",
      " 1. 2. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 2. 0. 2. 0. 0. 0.\n",
      " 0. 0. 2. 2. 2. 0. 0. 2. 1. 2. 1. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 1. 2.\n",
      " 1. 0. 0. 1. 1. 1. 2. 1. 1. 2. 0. 0. 0. 1. 2. 0. 0. 1. 2. 0. 0. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 0. 0. 1. 1. 0. 1. 0. 0. 2. 2. 0. 2. 2. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 2. 0. 1. 2. 1. 0. 1. 0. 2. 1. 0. 0. 0. 2. 0. 2. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 2. 2. 0. 1. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2.\n",
      " 1. 1. 0. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 1. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1.\n",
      " 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2.\n",
      " 0. 2. 0. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 1. 1. 1. 2. 1. 1. 2.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.6103542234332425 accuracy_test: 0.225\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.74      0.58       100\n",
      "         1.0       0.63      0.74      0.68        78\n",
      "         2.0       0.75      0.49      0.59       189\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       367\n",
      "   macro avg       0.62      0.66      0.62       367\n",
      "weighted avg       0.65      0.61      0.61       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.27      0.19        11\n",
      "         1.0       0.44      0.50      0.47         8\n",
      "         2.0       0.18      0.10      0.12        21\n",
      "\n",
      "   micro avg       0.23      0.23      0.23        40\n",
      "   macro avg       0.26      0.29      0.26        40\n",
      "weighted avg       0.23      0.23      0.21        40\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 2. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 2. 0. 1. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2. 1. 0. 2. 0.\n",
      " 0. 2. 0. 1. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 2. 0. 1. 0. 1. 0.\n",
      " 0. 0. 2. 1. 2. 2. 1. 1. 0. 2. 0. 2. 0. 0. 0. 1. 2. 1. 1. 1. 1. 1. 2. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 0. 2. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 2. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 2. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 1. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0.\n",
      " 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.4822888283378747 accuracy_test: 0.35\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.87      0.51       100\n",
      "         1.0       0.64      0.82      0.72        78\n",
      "         2.0       0.90      0.14      0.24       189\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       367\n",
      "   macro avg       0.63      0.61      0.49       367\n",
      "weighted avg       0.70      0.48      0.42       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.82      0.46        11\n",
      "         1.0       0.50      0.62      0.56         8\n",
      "         2.0       0.00      0.00      0.00        21\n",
      "\n",
      "   micro avg       0.35      0.35      0.35        40\n",
      "   macro avg       0.27      0.48      0.34        40\n",
      "weighted avg       0.19      0.35      0.24        40\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 2. 0. 2. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 2. 0. 1. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1. 0. 2. 0. 2. 0. 0. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 2. 2. 2. 1. 0. 1. 2. 1. 0. 1.\n",
      " 0. 2. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 2. 2. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0.\n",
      " 0. 0. 1. 2. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0.]\n",
      "[2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.4822888283378747 accuracy_test: 0.425\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.94      0.53       100\n",
      "         1.0       0.70      0.73      0.71        78\n",
      "         2.0       0.96      0.14      0.24       189\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       367\n",
      "   macro avg       0.67      0.60      0.49       367\n",
      "weighted avg       0.74      0.48      0.42       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.73      0.44        11\n",
      "         1.0       0.64      0.88      0.74         8\n",
      "         2.0       0.50      0.10      0.16        21\n",
      "\n",
      "   micro avg       0.42      0.42      0.42        40\n",
      "   macro avg       0.49      0.57      0.45        40\n",
      "weighted avg       0.48      0.42      0.35        40\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 2. 2. 2. 0. 2. 2. 0. 0. 2. 2. 2. 0. 0. 2. 0. 2. 0. 2. 0. 0. 0. 1.\n",
      " 1. 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 2. 0. 2. 2. 1. 1. 2. 0.\n",
      " 1. 0. 2. 0. 2. 0. 2. 0. 0. 0. 0. 2. 1. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 0. 0. 1. 2. 0. 1. 0. 0. 1. 2. 0. 0. 1. 2. 1. 0. 2.\n",
      " 0. 2. 2. 2. 1. 2. 0. 2. 0. 0. 0. 1. 1. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 2.\n",
      " 1. 1. 0. 0. 1. 2. 1. 2. 1. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 2. 2. 0. 0. 0. 0. 2. 1. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 0. 0. 2. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 1. 1. 0. 1. 0. 2.\n",
      " 0. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 1. 2. 0. 0. 2. 0. 0. 2. 0. 2. 0. 0. 2.\n",
      " 2. 0. 0. 0. 1. 1. 2. 0. 2. 0. 0. 2. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 1.\n",
      " 2. 2. 0. 2. 0. 1. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 2. 2. 0. 1. 1. 2. 0.\n",
      " 2. 1. 0. 2. 0. 2. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 0. 2. 1. 1. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 0. 1. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 1. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1.\n",
      " 1. 2. 0. 2. 0. 0. 1. 0. 2. 2. 1. 0. 0. 2. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.5858310626702997 accuracy_test: 0.35\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.83      0.54       100\n",
      "         1.0       0.91      0.53      0.67        78\n",
      "         2.0       0.81      0.48      0.60       189\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       367\n",
      "   macro avg       0.70      0.61      0.60       367\n",
      "weighted avg       0.72      0.59      0.60       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.55      0.35        11\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "         2.0       0.47      0.38      0.42        21\n",
      "\n",
      "   micro avg       0.35      0.35      0.35        40\n",
      "   macro avg       0.24      0.31      0.26        40\n",
      "weighted avg       0.32      0.35      0.32        40\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.74      0.44       111\n",
      "         1.0       0.39      0.45      0.42        86\n",
      "         2.0       0.42      0.10      0.16       210\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       407\n",
      "   macro avg       0.37      0.43      0.34       407\n",
      "weighted avg       0.38      0.35      0.29       407\n",
      "\n",
      "0.3464373464373464\n",
      "1.2906976744186047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 0. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 0. 2. 2.\n",
      " 0. 0. 2. 2. 2. 2. 0. 2. 1. 0. 2. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 1. 2. 2. 0. 0. 0. 2. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 2.\n",
      " 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1.\n",
      " 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 1. 1. 2. 1. 0. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 1. 2. 0. 0. 0. 1. 2. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 0. 2. 1. 2. 1. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 0. 1. 1. 2. 2. 2. 2. 1.\n",
      " 2. 0. 1. 2. 0. 2. 2. 0. 1. 2. 2. 0. 2. 2. 0. 2. 2. 1. 2. 0. 1. 1. 2. 0.\n",
      " 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2.\n",
      " 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 0. 0. 0. 0. 1. 2. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.8575342465753425 accuracy_test: 0.47619047619047616\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89        99\n",
      "         1.0       0.75      0.81      0.77        77\n",
      "         2.0       0.90      0.86      0.88       189\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       365\n",
      "   macro avg       0.84      0.85      0.85       365\n",
      "weighted avg       0.86      0.86      0.86       365\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.33      0.35        12\n",
      "         1.0       0.50      0.56      0.53         9\n",
      "         2.0       0.52      0.52      0.52        21\n",
      "\n",
      "   micro avg       0.48      0.48      0.48        42\n",
      "   macro avg       0.46      0.47      0.47        42\n",
      "weighted avg       0.47      0.48      0.47        42\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 2. 0. 1. 2. 2. 2. 1. 1. 2. 0. 1. 2. 2. 1. 2. 0. 2. 1.\n",
      " 0. 2. 1. 1. 2. 1. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 0. 1. 0. 2. 2. 0. 0. 2.\n",
      " 2. 2. 2. 0. 1. 2. 1. 2. 1. 0. 2. 1. 2. 2. 2. 2. 2. 1. 0. 2. 2. 2. 2. 2.\n",
      " 2. 0. 2. 1. 2. 2. 0. 0. 0. 2. 2. 2. 2. 1. 1. 1. 2. 1. 2. 1. 2. 1. 1. 2.\n",
      " 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 2. 1. 1.\n",
      " 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 0. 2. 1. 2. 2. 1. 0. 0. 0. 0. 0.\n",
      " 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 0.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 0. 2. 1. 0. 2. 0. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 0. 2. 1. 1. 1. 2. 2.\n",
      " 2. 2. 1. 2. 1. 1. 0. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 0. 2. 1. 2. 0. 1. 1.\n",
      " 0. 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1.\n",
      " 0. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 1. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1.\n",
      " 1. 2. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.825136612021858 accuracy_test: 0.4634146341463415\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.87      0.85       100\n",
      "         1.0       0.71      0.78      0.75        77\n",
      "         2.0       0.87      0.82      0.84       189\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       366\n",
      "   macro avg       0.81      0.82      0.81       366\n",
      "weighted avg       0.83      0.83      0.83       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.45      0.42        11\n",
      "         1.0       0.67      0.22      0.33         9\n",
      "         2.0       0.48      0.57      0.52        21\n",
      "\n",
      "   micro avg       0.46      0.46      0.46        41\n",
      "   macro avg       0.51      0.42      0.42        41\n",
      "weighted avg       0.50      0.46      0.45        41\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 2. 2. 0. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0. 2. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 1. 0. 2. 2. 2. 2.\n",
      " 2. 2. 2. 0. 1. 2. 1. 0. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 2. 2. 0. 0. 2. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1.\n",
      " 2. 0. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 1. 1.\n",
      " 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 2. 1. 2. 2. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 2. 0. 2. 1. 2. 1. 0. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 0. 0. 2. 0. 2. 1. 1. 1. 2.\n",
      " 2. 2. 1. 2. 0. 1. 1. 2. 2. 2. 0. 1. 2. 0. 0. 2. 2. 2. 0. 2. 2. 1. 2. 0.\n",
      " 1. 1. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0. 2. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1. 2.\n",
      " 1. 1. 0. 2. 0. 0. 1. 1. 2. 2. 0. 1. 0. 0. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.8579234972677595 accuracy_test: 0.3902439024390244\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.91      0.88       100\n",
      "         1.0       0.76      0.78      0.77        77\n",
      "         2.0       0.90      0.86      0.88       189\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       366\n",
      "   macro avg       0.84      0.85      0.84       366\n",
      "weighted avg       0.86      0.86      0.86       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.27      0.30        11\n",
      "         1.0       0.22      0.22      0.22         9\n",
      "         2.0       0.48      0.52      0.50        21\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        41\n",
      "   macro avg       0.34      0.34      0.34        41\n",
      "weighted avg       0.38      0.39      0.39        41\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 0. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 0. 2. 2.\n",
      " 0. 2. 2. 2. 0. 1. 2. 1. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 1. 2. 1. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 2. 1.\n",
      " 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 1. 2. 1. 0. 2. 2.\n",
      " 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 0.\n",
      " 1. 2. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 0. 1. 0.\n",
      " 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 0. 2. 1. 2. 1. 0. 2. 0. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 1. 1. 2. 1.\n",
      " 2. 2. 1. 2. 0. 1. 1. 2. 0. 2. 2. 0. 1. 2. 0. 2. 2. 2. 0. 2. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 0. 2. 2. 2. 0. 2. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2.\n",
      " 1. 0. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 0. 1. 1. 1. 2. 2. 0. 1. 1. 2. 1.\n",
      " 1. 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 2. 2. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.8387978142076503 accuracy_test: 0.7073170731707317\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85       100\n",
      "         1.0       0.74      0.81      0.77        77\n",
      "         2.0       0.88      0.85      0.86       189\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       366\n",
      "   macro avg       0.82      0.83      0.83       366\n",
      "weighted avg       0.84      0.84      0.84       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.82      0.72        11\n",
      "         1.0       0.83      0.56      0.67         9\n",
      "         2.0       0.71      0.71      0.71        21\n",
      "\n",
      "   micro avg       0.71      0.71      0.71        41\n",
      "   macro avg       0.73      0.70      0.70        41\n",
      "weighted avg       0.72      0.71      0.71        41\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 2. 0.\n",
      " 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 0. 2. 1. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 2. 2. 0. 2. 2.\n",
      " 2. 2. 1. 1. 0. 2. 1. 2. 0. 2. 1. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1. 1. 2. 2. 1. 1.\n",
      " 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 1. 1. 2. 1. 1. 1.\n",
      " 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 2. 0. 2. 0. 1. 2. 2. 2. 2. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0.\n",
      " 2. 2. 2. 1. 2. 2. 2. 2. 1. 0. 0. 2. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 0. 2. 1.\n",
      " 2. 1. 0. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0.\n",
      " 1. 1. 2. 0. 2. 2. 0. 2. 2. 0. 2. 2. 0. 2. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1.\n",
      " 2. 0. 1. 1. 2. 0. 2. 2. 2. 1. 0. 2. 0. 2. 2. 2. 0. 2. 2. 2. 0. 1. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 2. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 1.\n",
      " 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.8469945355191257 accuracy_test: 0.5853658536585366\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88       100\n",
      "         1.0       0.73      0.75      0.74        77\n",
      "         2.0       0.88      0.87      0.87       189\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       366\n",
      "   macro avg       0.83      0.83      0.83       366\n",
      "weighted avg       0.85      0.85      0.85       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.18      0.29        11\n",
      "         1.0       0.75      0.33      0.46         9\n",
      "         2.0       0.56      0.90      0.69        21\n",
      "\n",
      "   micro avg       0.59      0.59      0.59        41\n",
      "   macro avg       0.66      0.47      0.48        41\n",
      "weighted avg       0.63      0.59      0.53        41\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1. 1. 2. 2. 0. 2.\n",
      " 2. 0. 1. 2. 2. 2. 2. 1. 1. 2. 0. 1. 2. 2. 1. 2. 0. 2. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 0. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 2. 0. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 1. 1.\n",
      " 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 1. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 2. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 1. 0. 2. 1. 2. 1. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 0.\n",
      " 1. 1. 2. 0. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 1. 1. 2. 2. 2. 2. 1.\n",
      " 2. 0. 1. 1. 2. 0. 2. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 2. 2. 1. 2. 0. 1. 1.\n",
      " 2. 0. 2. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1. 1. 2. 2. 0. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.8442622950819673 accuracy_test: 0.5121951219512195\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.85      0.86       100\n",
      "         1.0       0.76      0.79      0.78        77\n",
      "         2.0       0.87      0.86      0.86       189\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       366\n",
      "   macro avg       0.83      0.83      0.83       366\n",
      "weighted avg       0.85      0.84      0.84       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.27      0.37        11\n",
      "         1.0       0.36      0.44      0.40         9\n",
      "         2.0       0.56      0.67      0.61        21\n",
      "\n",
      "   micro avg       0.51      0.51      0.51        41\n",
      "   macro avg       0.51      0.46      0.46        41\n",
      "weighted avg       0.53      0.51      0.50        41\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 0. 1. 1. 2. 2. 0. 2. 2. 1. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 0. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 1. 2. 1. 0. 2. 1. 2. 0. 2. 1. 2. 2. 2. 2. 2. 1. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 1. 1.\n",
      " 2. 0. 1. 2. 1. 2. 2. 2. 2. 1. 2. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 2.\n",
      " 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 1. 1. 2. 1. 2.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 1. 0. 2. 1. 2. 1. 0. 2. 2. 0. 2. 0. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 1. 1. 0. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 0. 0. 1. 1. 1. 2. 2.\n",
      " 2. 1. 0. 1. 1. 2. 0. 2. 2. 0. 1. 2. 0. 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 0. 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0.\n",
      " 0. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 1. 1.\n",
      " 2. 0. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.8446866485013624 accuracy_test: 0.575\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.88       100\n",
      "         1.0       0.75      0.77      0.76        78\n",
      "         2.0       0.87      0.86      0.86       189\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       367\n",
      "   macro avg       0.83      0.84      0.83       367\n",
      "weighted avg       0.85      0.84      0.84       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.18      0.24        11\n",
      "         1.0       0.70      0.88      0.78         8\n",
      "         2.0       0.58      0.67      0.62        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        40\n",
      "   macro avg       0.54      0.57      0.55        40\n",
      "weighted avg       0.54      0.57      0.55        40\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 0. 1. 2. 2. 2. 2. 1. 1. 2. 0. 1. 2. 2. 1. 2. 0. 1. 1.\n",
      " 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 0. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 1. 2. 1. 0. 2. 1. 2. 0. 2. 1. 2. 2. 2. 2. 2. 2. 1. 0.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 0. 2. 2. 2. 2. 1. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 2. 0. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2.\n",
      " 2. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 1. 1. 1. 1. 1. 2. 0. 2. 2. 2. 2. 2. 1. 0. 2. 0. 2. 1. 1. 2. 1. 0.\n",
      " 2. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 0. 0. 1. 2.\n",
      " 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 0. 2. 1. 2. 2. 2. 2. 1. 0. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 0. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 0. 2. 1. 1. 1. 2.\n",
      " 2. 2. 2. 0. 1. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 0. 2. 2. 1. 2. 0. 1. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0.\n",
      " 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0.\n",
      " 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2.\n",
      " 1. 2. 2. 0. 1. 1. 0. 2. 2. 0. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.8501362397820164 accuracy_test: 0.525\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.90      0.87       100\n",
      "         1.0       0.77      0.82      0.80        78\n",
      "         2.0       0.89      0.84      0.86       189\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       367\n",
      "   macro avg       0.83      0.85      0.84       367\n",
      "weighted avg       0.85      0.85      0.85       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.36      0.44        11\n",
      "         1.0       0.20      0.25      0.22         8\n",
      "         2.0       0.65      0.71      0.68        21\n",
      "\n",
      "   micro avg       0.53      0.53      0.53        40\n",
      "   macro avg       0.47      0.44      0.45        40\n",
      "weighted avg       0.54      0.53      0.52        40\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2.\n",
      " 0. 2. 2. 0. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 0. 2. 1. 1. 0. 1. 1. 2.\n",
      " 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 2. 2. 2. 0. 2. 2. 2.\n",
      " 0. 1. 2. 1. 2. 2. 1. 2. 0. 2. 1. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1. 2. 0. 1. 2.\n",
      " 1. 1. 2. 2. 2. 2. 1. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 1.\n",
      " 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 0. 2. 1. 2. 2. 1. 0. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 0. 0. 2. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 2. 0. 2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 0. 2. 2. 2. 2. 2. 0. 2. 0. 1. 1. 1. 2. 2. 2. 2. 1.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 0. 1. 1.\n",
      " 1. 0. 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1.\n",
      " 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 1. 2. 2. 1. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.8337874659400545 accuracy_test: 0.5\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.88      0.87       100\n",
      "         1.0       0.72      0.76      0.74        78\n",
      "         2.0       0.87      0.84      0.85       189\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       367\n",
      "   macro avg       0.82      0.83      0.82       367\n",
      "weighted avg       0.84      0.83      0.83       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.27      0.35        11\n",
      "         1.0       0.38      0.38      0.38         8\n",
      "         2.0       0.54      0.67      0.60        21\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        40\n",
      "   macro avg       0.47      0.44      0.44        40\n",
      "weighted avg       0.50      0.50      0.48        40\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 0. 1. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2. 1. 2. 0. 2. 1. 1. 2.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 0. 2. 2.\n",
      " 0. 2. 2. 2. 0. 1. 2. 1. 0. 2. 1. 2. 0. 2. 1. 2. 2. 2. 2. 2. 1. 2. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 2. 1. 1.\n",
      " 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 1.\n",
      " 2. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 1. 1. 2. 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 0. 2. 1. 2. 2.\n",
      " 1. 0. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0.\n",
      " 0. 2. 0. 0. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 2. 0. 1. 2. 0. 2. 2.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2.\n",
      " 0. 2. 0. 2. 2. 2. 2. 0. 1. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 1. 2. 2.\n",
      " 2. 1. 2. 0. 1. 1. 2. 0. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 0. 2. 1. 2. 0. 1.\n",
      " 1. 2. 2. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0.\n",
      " 2. 1. 0. 0. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2.\n",
      " 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2.\n",
      " 0. 2. 0. 2. 2. 2. 2. 0. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 0. 2. 1. 2. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.8446866485013624 accuracy_test: 0.55\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.90       100\n",
      "         1.0       0.74      0.74      0.74        78\n",
      "         2.0       0.86      0.86      0.86       189\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       367\n",
      "   macro avg       0.83      0.83      0.83       367\n",
      "weighted avg       0.84      0.84      0.84       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.64      0.54        11\n",
      "         1.0       0.40      0.25      0.31         8\n",
      "         2.0       0.65      0.62      0.63        21\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        40\n",
      "   macro avg       0.51      0.50      0.49        40\n",
      "weighted avg       0.55      0.55      0.54        40\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.38      0.42       111\n",
      "         1.0       0.46      0.41      0.43        86\n",
      "         2.0       0.57      0.66      0.61       210\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       407\n",
      "   macro avg       0.50      0.48      0.49       407\n",
      "weighted avg       0.52      0.53      0.52       407\n",
      "\n",
      "0.5282555282555282\n",
      "1.2906976744186047\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 1. 1. 2. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 1. 1. 2. 2. 1. 2. 2. 2. 0. 1. 1. 0. 2. 1. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2. 0.\n",
      " 2. 2. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 0. 0. 0. 1. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 2. 0. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2. 2. 0. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 1. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 2. 0. 1. 1. 2. 1. 2. 2.\n",
      " 0. 2. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 1. 0. 2. 1. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 0. 0. 0. 1. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.9671232876712329 accuracy_test: 0.6190476190476191\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96        99\n",
      "         1.0       0.97      0.99      0.98        77\n",
      "         2.0       0.98      0.96      0.97       189\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       365\n",
      "   macro avg       0.96      0.97      0.97       365\n",
      "weighted avg       0.97      0.97      0.97       365\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.58      0.54        12\n",
      "         1.0       0.83      0.56      0.67         9\n",
      "         2.0       0.64      0.67      0.65        21\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        42\n",
      "   macro avg       0.66      0.60      0.62        42\n",
      "weighted avg       0.64      0.62      0.62        42\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 1. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 2.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 2. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 1. 1. 1. 2. 0. 0. 0. 1. 2. 1.\n",
      " 2. 2. 0. 0. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 2.\n",
      " 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 2. 1. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2. 1.\n",
      " 1. 2. 0. 0. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9672131147540983 accuracy_test: 0.5365853658536586\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       100\n",
      "         1.0       0.97      0.99      0.98        77\n",
      "         2.0       0.97      0.96      0.97       189\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       366\n",
      "   macro avg       0.97      0.97      0.97       366\n",
      "weighted avg       0.97      0.97      0.97       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.55      0.55        11\n",
      "         1.0       0.43      0.33      0.38         9\n",
      "         2.0       0.57      0.62      0.59        21\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        41\n",
      "   macro avg       0.51      0.50      0.50        41\n",
      "weighted avg       0.53      0.54      0.53        41\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 2. 0. 0.\n",
      " 0. 1. 1. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 1. 1. 2. 2. 1. 2. 2. 1. 2. 1.\n",
      " 1. 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 2. 1. 2. 1. 2. 1. 2. 1.\n",
      " 2. 0. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 1. 0. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1.\n",
      " 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 2. 0. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 2. 0. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 0. 1. 1. 2. 0. 0. 0. 1. 1.\n",
      " 1. 2. 2. 0. 2. 0. 0. 1. 1. 2. 0. 1. 0. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 0. 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 1.\n",
      " 1. 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 2. 1. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1.\n",
      " 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 2. 0. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1.\n",
      " 1. 1. 2. 0. 2. 0. 0. 1. 1. 2. 0. 1. 0. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.9590163934426229 accuracy_test: 0.6341463414634146\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       100\n",
      "         1.0       0.96      0.99      0.97        77\n",
      "         2.0       0.97      0.95      0.96       189\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       366\n",
      "   macro avg       0.96      0.96      0.96       366\n",
      "weighted avg       0.96      0.96      0.96       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.45      0.48        11\n",
      "         1.0       0.67      0.44      0.53         9\n",
      "         2.0       0.68      0.81      0.74        21\n",
      "\n",
      "   micro avg       0.63      0.63      0.63        41\n",
      "   macro avg       0.62      0.57      0.58        41\n",
      "weighted avg       0.63      0.63      0.62        41\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 1. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2.\n",
      " 0. 2. 1. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 1. 0. 2. 2. 2.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 1. 1. 1.\n",
      " 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 1. 1. 2. 2. 2. 2. 0. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 1. 2. 2. 0.\n",
      " 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 1.\n",
      " 0. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 0. 1. 0. 1. 1. 2. 1. 2. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 1. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2.\n",
      " 0. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1.\n",
      " 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 0. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 1. 2. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1.\n",
      " 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9644808743169399 accuracy_test: 0.5365853658536586\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       100\n",
      "         1.0       0.97      0.97      0.97        77\n",
      "         2.0       0.97      0.96      0.97       189\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       366\n",
      "   macro avg       0.96      0.97      0.96       366\n",
      "weighted avg       0.96      0.96      0.96       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.27      0.32        11\n",
      "         1.0       0.44      0.44      0.44         9\n",
      "         2.0       0.62      0.71      0.67        21\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        41\n",
      "   macro avg       0.48      0.48      0.48        41\n",
      "weighted avg       0.52      0.54      0.52        41\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2.\n",
      " 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 1. 2.\n",
      " 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 1. 0. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 0. 0. 0. 1. 1. 2. 1. 2. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 1. 2.\n",
      " 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9754098360655737 accuracy_test: 0.36585365853658536\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       100\n",
      "         1.0       0.97      0.99      0.98        77\n",
      "         2.0       0.98      0.97      0.98       189\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       366\n",
      "   macro avg       0.97      0.98      0.98       366\n",
      "weighted avg       0.98      0.98      0.98       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.09      0.11        11\n",
      "         1.0       0.12      0.11      0.12         9\n",
      "         2.0       0.50      0.62      0.55        21\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        41\n",
      "   macro avg       0.26      0.27      0.26        41\n",
      "weighted avg       0.32      0.37      0.34        41\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 1. 2. 0. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 1.\n",
      " 1. 1. 1. 1. 1. 0. 2. 1. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 0. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 2. 2.\n",
      " 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 2.\n",
      " 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9699453551912568 accuracy_test: 0.5853658536585366\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96       100\n",
      "         1.0       0.99      0.97      0.98        77\n",
      "         2.0       0.97      0.97      0.97       189\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       366\n",
      "   macro avg       0.97      0.97      0.97       366\n",
      "weighted avg       0.97      0.97      0.97       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.55      0.55        11\n",
      "         1.0       0.50      0.33      0.40         9\n",
      "         2.0       0.62      0.71      0.67        21\n",
      "\n",
      "   micro avg       0.59      0.59      0.59        41\n",
      "   macro avg       0.56      0.53      0.54        41\n",
      "weighted avg       0.58      0.59      0.58        41\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 0. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2.\n",
      " 2. 1. 2. 1. 1. 1. 1. 0. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2.\n",
      " 0. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 1. 0. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0.\n",
      " 2. 0. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 0. 0. 0. 1. 2.\n",
      " 1. 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 2. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 2. 1. 2. 1. 1. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2.\n",
      " 0. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0.\n",
      " 2. 0. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 2. 1. 1. 1. 2. 0. 2. 0. 1. 2.\n",
      " 1. 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0.]\n",
      "accuracy_train: 0.9727520435967303 accuracy_test: 0.525\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97       100\n",
      "         1.0       0.99      0.96      0.97        78\n",
      "         2.0       0.98      0.96      0.97       189\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       367\n",
      "   macro avg       0.97      0.97      0.97       367\n",
      "weighted avg       0.97      0.97      0.97       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      0.27      0.29        11\n",
      "         1.0       0.62      0.62      0.62         8\n",
      "         2.0       0.59      0.62      0.60        21\n",
      "\n",
      "   micro avg       0.53      0.53      0.53        40\n",
      "   macro avg       0.51      0.51      0.51        40\n",
      "weighted avg       0.52      0.53      0.52        40\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0. 1. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 1.\n",
      " 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 0. 1. 1. 2. 1. 2. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0. 1. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1.\n",
      " 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9809264305177112 accuracy_test: 0.475\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       100\n",
      "         1.0       1.00      0.97      0.99        78\n",
      "         2.0       0.98      0.98      0.98       189\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       367\n",
      "   macro avg       0.98      0.98      0.98       367\n",
      "weighted avg       0.98      0.98      0.98       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.55      0.48        11\n",
      "         1.0       0.33      0.38      0.35         8\n",
      "         2.0       0.59      0.48      0.53        21\n",
      "\n",
      "   micro avg       0.47      0.47      0.48        40\n",
      "   macro avg       0.45      0.47      0.45        40\n",
      "weighted avg       0.49      0.47      0.48        40\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 0. 2.\n",
      " 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 0. 1. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 1. 2. 0. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 0. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 1. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1.\n",
      " 2. 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 0. 2. 2. 2. 2. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 0. 2.\n",
      " 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1.\n",
      " 1. 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9618528610354223 accuracy_test: 0.55\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95       100\n",
      "         1.0       0.95      0.99      0.97        78\n",
      "         2.0       0.97      0.96      0.96       189\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       367\n",
      "   macro avg       0.96      0.96      0.96       367\n",
      "weighted avg       0.96      0.96      0.96       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.36      0.40        11\n",
      "         1.0       0.50      0.50      0.50         8\n",
      "         2.0       0.61      0.67      0.64        21\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        40\n",
      "   macro avg       0.52      0.51      0.51        40\n",
      "weighted avg       0.54      0.55      0.54        40\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 1. 2. 0. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1.\n",
      " 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 2. 0. 1. 0. 1. 1. 2. 1. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1.\n",
      " 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.9700272479564033 accuracy_test: 0.5\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96       100\n",
      "         1.0       0.96      0.99      0.97        78\n",
      "         2.0       0.97      0.97      0.97       189\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       367\n",
      "   macro avg       0.97      0.97      0.97       367\n",
      "weighted avg       0.97      0.97      0.97       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.18      0.20        11\n",
      "         1.0       0.55      0.75      0.63         8\n",
      "         2.0       0.60      0.57      0.59        21\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        40\n",
      "   macro avg       0.46      0.50      0.47        40\n",
      "weighted avg       0.49      0.50      0.49        40\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.39      0.40       111\n",
      "         1.0       0.49      0.44      0.46        86\n",
      "         2.0       0.60      0.65      0.62       210\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       407\n",
      "   macro avg       0.50      0.49      0.50       407\n",
      "weighted avg       0.53      0.53      0.53       407\n",
      "\n",
      "0.5331695331695332\n",
      "1.2906976744186047\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 1. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 1. 2. 1. 2. 2.\n",
      " 1. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 1. 2. 2. 2. 2. 0.\n",
      " 2. 0. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2.\n",
      " 0. 0. 0. 0. 2. 2. 2. 0. 0. 2. 2. 2. 2. 2. 0. 1. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 2. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 0. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0. 1. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 2. 0. 2. 2. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.6383561643835617 accuracy_test: 0.5714285714285714\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.32      0.47        99\n",
      "         1.0       0.74      0.32      0.45        77\n",
      "         2.0       0.60      0.93      0.73       189\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       365\n",
      "   macro avg       0.73      0.53      0.55       365\n",
      "weighted avg       0.69      0.64      0.60       365\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.25      0.38        12\n",
      "         1.0       0.67      0.22      0.33         9\n",
      "         2.0       0.54      0.90      0.68        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        42\n",
      "   macro avg       0.65      0.46      0.46        42\n",
      "weighted avg       0.63      0.57      0.52        42\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 2. 0. 0. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 0. 0. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 1. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 1. 0. 2. 0. 2. 0. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 2. 2. 2. 0. 0. 2. 0. 0. 2. 2. 2. 2.\n",
      " 2. 0. 0. 0. 0. 2. 2. 2. 0. 0. 2. 2. 0. 0. 0. 0. 2. 2. 2. 2. 0. 2. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0.\n",
      " 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 2.\n",
      " 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 0. 1. 1.\n",
      " 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2. 0.\n",
      " 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.6311475409836066 accuracy_test: 0.4146341463414634\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.46      0.54       100\n",
      "         1.0       0.94      0.19      0.32        77\n",
      "         2.0       0.61      0.90      0.73       189\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       366\n",
      "   macro avg       0.73      0.52      0.53       366\n",
      "weighted avg       0.69      0.63      0.59       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.18      0.20        11\n",
      "         1.0       0.50      0.11      0.18         9\n",
      "         2.0       0.47      0.67      0.55        21\n",
      "\n",
      "   micro avg       0.41      0.41      0.41        41\n",
      "   macro avg       0.40      0.32      0.31        41\n",
      "weighted avg       0.41      0.41      0.37        41\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 0. 1. 2. 1. 0. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 2. 0.\n",
      " 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 2. 2. 0. 0. 0. 1. 0. 0. 2.\n",
      " 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 2. 0. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 1. 0. 1. 1. 2. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 2. 0. 2. 0. 2. 2. 0. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 1. 2. 2. 2. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1.\n",
      " 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.8688524590163934 accuracy_test: 0.5609756097560976\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.83      0.86       100\n",
      "         1.0       0.86      0.78      0.82        77\n",
      "         2.0       0.86      0.93      0.89       189\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       366\n",
      "   macro avg       0.87      0.85      0.86       366\n",
      "weighted avg       0.87      0.87      0.87       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.27      0.33        11\n",
      "         1.0       0.50      0.33      0.40         9\n",
      "         2.0       0.61      0.81      0.69        21\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        41\n",
      "   macro avg       0.51      0.47      0.48        41\n",
      "weighted avg       0.54      0.56      0.53        41\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 2. 0. 0. 2. 0.\n",
      " 0. 2. 2. 0. 2. 0. 0. 0. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 0. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 1. 2. 1. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 2. 1.\n",
      " 1. 2. 1. 2. 1. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 1. 2. 1. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 1. 0. 2. 2. 0. 0. 2. 0. 2. 2. 0.\n",
      " 0. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 2. 2. 0. 0. 1. 0. 0. 2. 0. 2. 0. 2.\n",
      " 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 2. 2.\n",
      " 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 1. 0. 1. 2. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 1.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 0. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1.\n",
      " 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 2. 2. 0. 1. 0. 0. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.6912568306010929 accuracy_test: 0.5853658536585366\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.53      0.63       100\n",
      "         1.0       0.76      0.45      0.57        77\n",
      "         2.0       0.66      0.87      0.75       189\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       366\n",
      "   macro avg       0.73      0.62      0.65       366\n",
      "weighted avg       0.71      0.69      0.68       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.36      0.50        11\n",
      "         1.0       0.33      0.11      0.17         9\n",
      "         2.0       0.58      0.90      0.70        21\n",
      "\n",
      "   micro avg       0.59      0.59      0.59        41\n",
      "   macro avg       0.57      0.46      0.46        41\n",
      "weighted avg       0.58      0.59      0.53        41\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 2.\n",
      " 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2.\n",
      " 2. 1. 1. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 0. 2. 2. 2. 1. 2. 2. 2.\n",
      " 0. 2. 2. 0. 2. 0. 0. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 0. 0. 2. 2. 2. 2. 0. 2. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 1.\n",
      " 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 0. 0.\n",
      " 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 1. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 2.\n",
      " 0. 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 0.6147540983606558 accuracy_test: 0.43902439024390244\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.28      0.40       100\n",
      "         1.0       0.88      0.27      0.42        77\n",
      "         2.0       0.58      0.93      0.72       189\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       366\n",
      "   macro avg       0.72      0.49      0.51       366\n",
      "weighted avg       0.68      0.61      0.57       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.27      0.33        11\n",
      "         1.0       0.25      0.11      0.15         9\n",
      "         2.0       0.47      0.67      0.55        21\n",
      "\n",
      "   micro avg       0.44      0.44      0.44        41\n",
      "   macro avg       0.38      0.35      0.35        41\n",
      "weighted avg       0.41      0.44      0.40        41\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2. 1. 2. 0. 2. 1. 1. 0. 2. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1. 2. 2. 1. 2.\n",
      " 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 2. 1. 1. 1. 1. 2. 1. 2. 1. 2. 2. 1. 1. 2. 2. 1. 1. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 1. 2. 2. 2. 0. 1. 2. 0.\n",
      " 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0.\n",
      " 0. 2. 0. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2. 2. 2.\n",
      " 2. 0. 0. 2. 0. 2. 0. 2. 2. 0. 2. 2. 2. 0. 0. 2. 1. 0. 0. 2. 2. 2. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 0. 1. 2. 0. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 1. 2. 2. 2. 2. 0. 2.\n",
      " 0. 0. 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 1. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 1. 2. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2.\n",
      " 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.6775956284153005 accuracy_test: 0.6097560975609756\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.41      0.56       100\n",
      "         1.0       0.66      0.52      0.58        77\n",
      "         2.0       0.64      0.88      0.75       189\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       366\n",
      "   macro avg       0.73      0.60      0.63       366\n",
      "weighted avg       0.71      0.68      0.66       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.18      0.27        11\n",
      "         1.0       0.83      0.56      0.67         9\n",
      "         2.0       0.58      0.86      0.69        21\n",
      "\n",
      "   micro avg       0.61      0.61      0.61        41\n",
      "   macro avg       0.64      0.53      0.54        41\n",
      "weighted avg       0.61      0.61      0.57        41\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 2. 0. 0. 2. 0. 0. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 0. 0. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 2. 2. 1. 0. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1. 2. 2. 1.\n",
      " 1. 1. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 2.\n",
      " 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 1. 0. 2. 2. 1. 0. 2. 0.\n",
      " 0. 2. 0. 0. 0. 2. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2.\n",
      " 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 2. 2. 2. 2. 2. 0. 1. 0. 0. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 2. 2. 1. 0. 0. 1. 2. 2. 2. 2. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 0. 0. 0. 2. 2. 1. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0. 2.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 0. 2. 2.\n",
      " 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 0. 0. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2.\n",
      " 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0.\n",
      " 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 0. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 1. 1. 2. 0. 2. 0. 1. 1. 2.\n",
      " 1. 1. 2. 0. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.7002724795640327 accuracy_test: 0.55\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.46      0.58       100\n",
      "         1.0       0.71      0.63      0.67        78\n",
      "         2.0       0.68      0.86      0.76       189\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       367\n",
      "   macro avg       0.73      0.65      0.67       367\n",
      "weighted avg       0.71      0.70      0.69       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.18      0.25        11\n",
      "         1.0       0.50      0.38      0.43         8\n",
      "         2.0       0.59      0.81      0.68        21\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        40\n",
      "   macro avg       0.50      0.46      0.45        40\n",
      "weighted avg       0.52      0.55      0.51        40\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 0. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 0. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 1. 1. 0. 2. 2.\n",
      " 1. 2. 1. 1. 2. 2. 1. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 2.\n",
      " 2. 1. 1. 1. 1. 1. 0. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 2. 2. 2.\n",
      " 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2.\n",
      " 2. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 2. 2. 0. 0. 0.\n",
      " 1. 0. 0. 2. 1. 0. 1. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 0. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 0. 2. 0. 2. 0. 1.\n",
      " 2. 1. 2. 2. 0. 2. 0. 2. 1. 0. 2. 2. 0. 1. 0. 0. 2. 2. 2. 2. 0. 2. 1. 2.\n",
      " 0. 2. 1. 0. 2. 2. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 2. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2.\n",
      " 1. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 1. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1.\n",
      " 2. 1. 1. 2. 0. 2. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 2. 2. 2. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0.]\n",
      "accuracy_train: 0.8746594005449592 accuracy_test: 0.65\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.84      0.87       100\n",
      "         1.0       0.88      0.77      0.82        78\n",
      "         2.0       0.86      0.94      0.90       189\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       367\n",
      "   macro avg       0.88      0.85      0.86       367\n",
      "weighted avg       0.88      0.87      0.87       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.55      0.63        11\n",
      "         1.0       0.57      0.50      0.53         8\n",
      "         2.0       0.64      0.76      0.70        21\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        40\n",
      "   macro avg       0.65      0.60      0.62        40\n",
      "weighted avg       0.66      0.65      0.65        40\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 0. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 1. 1. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 1. 1.\n",
      " 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 1. 0. 2. 2. 2. 2. 2. 0. 2.\n",
      " 2. 0. 0. 2. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2. 2. 0.\n",
      " 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 2. 2. 2. 2. 0. 2. 2. 0. 0. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 2. 2. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2.\n",
      " 2. 0. 0. 2. 2. 2. 2. 2. 2. 0. 1. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2.\n",
      " 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 0. 0. 1. 2. 2. 1. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 0. 1. 2. 1.\n",
      " 2. 2. 0. 0. 1. 0. 2. 2. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.6239782016348774 accuracy_test: 0.525\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.36      0.47       100\n",
      "         1.0       0.82      0.29      0.43        78\n",
      "         2.0       0.59      0.90      0.71       189\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       367\n",
      "   macro avg       0.70      0.52      0.54       367\n",
      "weighted avg       0.67      0.62      0.59       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.18      0.25        11\n",
      "         1.0       1.00      0.12      0.22         8\n",
      "         2.0       0.53      0.86      0.65        21\n",
      "\n",
      "   micro avg       0.53      0.53      0.53        40\n",
      "   macro avg       0.64      0.39      0.38        40\n",
      "weighted avg       0.59      0.53      0.46        40\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1.\n",
      " 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1.\n",
      " 1. 2. 1. 2. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2.\n",
      " 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 1. 2. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1. 1.\n",
      " 1. 2. 0. 2. 0. 1. 1. 0. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.5504087193460491 accuracy_test: 0.575\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04       100\n",
      "         1.0       0.82      0.18      0.29        78\n",
      "         2.0       0.53      0.98      0.69       189\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       367\n",
      "   macro avg       0.79      0.39      0.34       367\n",
      "weighted avg       0.72      0.55      0.43       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       1.00      0.25      0.40         8\n",
      "         2.0       0.55      1.00      0.71        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        40\n",
      "   macro avg       0.52      0.42      0.37        40\n",
      "weighted avg       0.49      0.57      0.45        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.24      0.33       111\n",
      "         1.0       0.57      0.27      0.37        86\n",
      "         2.0       0.55      0.82      0.66       210\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       407\n",
      "   macro avg       0.54      0.44      0.45       407\n",
      "weighted avg       0.54      0.55      0.51       407\n",
      "\n",
      "0.547911547911548\n",
      "1.2906976744186047\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0.\n",
      " 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1.\n",
      " 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 0. 2. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 2. 0. 1. 1. 1. 2. 2. 1. 2. 2. 1. 2. 0. 2. 0. 1. 1. 2. 1. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0.\n",
      " 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2.\n",
      " 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1.\n",
      " 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 0. 2. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 2. 0. 1. 1. 1. 2. 2. 1. 2. 2. 1. 2. 0. 2. 0. 1. 1. 2. 1. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5238095238095238\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        99\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       365\n",
      "   macro avg       1.00      1.00      1.00       365\n",
      "weighted avg       1.00      1.00      1.00       365\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        12\n",
      "         1.0       1.00      0.11      0.20         9\n",
      "         2.0       0.51      1.00      0.68        21\n",
      "\n",
      "   micro avg       0.52      0.52      0.52        42\n",
      "   macro avg       0.50      0.37      0.29        42\n",
      "weighted avg       0.47      0.52      0.38        42\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 1. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1.\n",
      " 0. 0. 0. 0. 1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2.\n",
      " 1. 1. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 2. 2. 2. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 0. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 1. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1.\n",
      " 0. 0. 0. 0. 1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2.\n",
      " 1. 1. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 2. 2. 2. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5365853658536586\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.09      0.15        11\n",
      "         1.0       0.67      0.22      0.33         9\n",
      "         2.0       0.53      0.90      0.67        21\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        41\n",
      "   macro avg       0.56      0.41      0.38        41\n",
      "weighted avg       0.55      0.54      0.46        41\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 0. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 0. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5609756097560976\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.75      0.33      0.46         9\n",
      "         2.0       0.54      0.95      0.69        21\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        41\n",
      "   macro avg       0.43      0.43      0.38        41\n",
      "weighted avg       0.44      0.56      0.45        41\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 0. 2.\n",
      " 2. 2. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 0. 2. 0. 1. 1. 2. 1. 2.\n",
      " 0. 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 0. 2. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 0. 2.\n",
      " 2. 2. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 0. 2. 0. 1. 1. 2. 1. 2.\n",
      " 0. 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 0. 2. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5121951219512195\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.67      0.22      0.33         9\n",
      "         2.0       0.51      0.90      0.66        21\n",
      "\n",
      "   micro avg       0.51      0.51      0.51        41\n",
      "   macro avg       0.39      0.38      0.33        41\n",
      "weighted avg       0.41      0.51      0.41        41\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 1. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 2. 2.\n",
      " 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 2. 2. 0.\n",
      " 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0.]\n",
      "[2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 1. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 2. 2.\n",
      " 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 0. 2. 2. 2. 2. 0.\n",
      " 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5365853658536586\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       1.00      0.11      0.20         9\n",
      "         2.0       0.53      1.00      0.69        21\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        41\n",
      "   macro avg       0.51      0.37      0.30        41\n",
      "weighted avg       0.49      0.54      0.40        41\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0. 0. 0.\n",
      " 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1.\n",
      " 2. 1. 1. 2. 0. 2. 0. 1. 1. 2. 2. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0. 0. 0.\n",
      " 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1.\n",
      " 2. 1. 1. 2. 0. 2. 0. 1. 1. 2. 2. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5609756097560976\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.27      0.40        11\n",
      "         1.0       0.43      0.33      0.38         9\n",
      "         2.0       0.57      0.81      0.67        21\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        41\n",
      "   macro avg       0.58      0.47      0.48        41\n",
      "weighted avg       0.59      0.56      0.53        41\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 0.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0.\n",
      " 2. 0. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 0.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0.\n",
      " 2. 0. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 1. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.575\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.75      0.38      0.50         8\n",
      "         2.0       0.57      0.95      0.71        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        40\n",
      "   macro avg       0.44      0.44      0.40        40\n",
      "weighted avg       0.45      0.57      0.47        40\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 0. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 1. 2. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 0. 2. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 2. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 0. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 1. 2. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 0. 2. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 2. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.55\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.67      0.25      0.36         8\n",
      "         2.0       0.54      0.95      0.69        21\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        40\n",
      "   macro avg       0.40      0.40      0.35        40\n",
      "weighted avg       0.42      0.55      0.43        40\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 1.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 1.\n",
      " 1. 2. 1. 1. 2. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 1. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 1.\n",
      " 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2.\n",
      " 0. 2. 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 1.\n",
      " 1. 2. 1. 1. 2. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.575\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       1.00      0.38      0.55         8\n",
      "         2.0       0.56      0.95      0.70        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        40\n",
      "   macro avg       0.52      0.44      0.42        40\n",
      "weighted avg       0.49      0.57      0.48        40\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2.\n",
      " 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 2.\n",
      " 1. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 1.\n",
      " 1. 2. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 0. 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 0. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2.\n",
      " 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 1. 2. 2.\n",
      " 1. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2. 2. 2. 0. 1.\n",
      " 1. 2. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2. 0. 2.\n",
      " 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.575\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.09      0.15        11\n",
      "         1.0       0.67      0.25      0.36         8\n",
      "         2.0       0.57      0.95      0.71        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        40\n",
      "   macro avg       0.58      0.43      0.41        40\n",
      "weighted avg       0.57      0.57      0.49        40\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.05      0.08       111\n",
      "         1.0       0.69      0.26      0.37        86\n",
      "         2.0       0.54      0.94      0.69       210\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       407\n",
      "   macro avg       0.56      0.41      0.38       407\n",
      "weighted avg       0.55      0.55      0.46       407\n",
      "\n",
      "0.5503685503685504\n",
      "1.2906976744186047\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
      " 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1.\n",
      " 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 0. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.47619047619047616\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        99\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       365\n",
      "   macro avg       1.00      1.00      1.00       365\n",
      "weighted avg       1.00      1.00      1.00       365\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.33      0.35        12\n",
      "         1.0       0.40      0.67      0.50         9\n",
      "         2.0       0.62      0.48      0.54        21\n",
      "\n",
      "   micro avg       0.48      0.48      0.48        42\n",
      "   macro avg       0.46      0.49      0.46        42\n",
      "weighted avg       0.50      0.48      0.48        42\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0. 0. 1. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 0. 1. 1. 2. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 2. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 0. 0. 1. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
      " 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0.\n",
      " 2. 2. 2. 2. 0. 1. 1. 2. 2. 2. 2. 1. 2. 2. 0. 1. 1. 2. 0. 2. 0. 1. 2. 1.\n",
      " 2. 0. 2. 0. 0. 1. 1. 0. 2. 1. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.6341463414634146\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.45      0.48        11\n",
      "         1.0       0.57      0.44      0.50         9\n",
      "         2.0       0.71      0.81      0.76        21\n",
      "\n",
      "   micro avg       0.63      0.63      0.63        41\n",
      "   macro avg       0.59      0.57      0.58        41\n",
      "weighted avg       0.62      0.63      0.62        41\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2.\n",
      " 1. 1. 2. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1. 0. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 1. 2. 1. 2. 2. 2. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2.\n",
      " 1. 1. 2. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5609756097560976\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.64      0.56        11\n",
      "         1.0       0.40      0.44      0.42         9\n",
      "         2.0       0.71      0.57      0.63        21\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        41\n",
      "   macro avg       0.54      0.55      0.54        41\n",
      "weighted avg       0.58      0.56      0.57        41\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1.\n",
      " 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 0. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2. 1. 1. 2.\n",
      " 0. 2. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 0. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2. 2. 2. 2. 0.\n",
      " 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 0. 1. 2. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1.\n",
      " 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 0. 2. 2. 2. 0. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 2. 1. 1. 2.\n",
      " 0. 2. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5365853658536586\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.45      0.42        11\n",
      "         1.0       0.50      0.44      0.47         9\n",
      "         2.0       0.65      0.62      0.63        21\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        41\n",
      "   macro avg       0.51      0.51      0.51        41\n",
      "weighted avg       0.55      0.54      0.54        41\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 0. 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1.\n",
      " 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 0. 1. 1. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0.\n",
      " 0. 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 1. 1. 0.\n",
      " 2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2. 2. 2.\n",
      " 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1.\n",
      " 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0.\n",
      " 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 0. 1. 1. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 0. 2. 2. 0. 1. 0. 2. 0. 2. 2. 2. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.3170731707317073\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.45      0.33        11\n",
      "         1.0       0.29      0.22      0.25         9\n",
      "         2.0       0.40      0.29      0.33        21\n",
      "\n",
      "   micro avg       0.32      0.32      0.32        41\n",
      "   macro avg       0.32      0.32      0.31        41\n",
      "weighted avg       0.34      0.32      0.32        41\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 1. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 2. 0. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 1. 1. 2.\n",
      " 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1. 0. 2. 1. 1.\n",
      " 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 0. 0. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 2. 0. 1. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 2. 0. 0. 1. 1. 2. 1. 1. 2. 0.\n",
      " 2. 0. 0. 1. 1. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.5121951219512195\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        77\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.55      0.50        11\n",
      "         1.0       0.29      0.22      0.25         9\n",
      "         2.0       0.62      0.62      0.62        21\n",
      "\n",
      "   micro avg       0.51      0.51      0.51        41\n",
      "   macro avg       0.46      0.46      0.46        41\n",
      "weighted avg       0.50      0.51      0.51        41\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2.\n",
      " 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0.\n",
      " 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 1.\n",
      " 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 1. 0. 2.\n",
      " 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0.\n",
      " 0. 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 2. 2. 1. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.625\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.36      0.44        11\n",
      "         1.0       0.57      0.50      0.53         8\n",
      "         2.0       0.65      0.81      0.72        21\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        40\n",
      "   macro avg       0.60      0.56      0.57        40\n",
      "weighted avg       0.61      0.62      0.61        40\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1.\n",
      " 1. 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1.\n",
      " 1. 0. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0.\n",
      " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
      " 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 0. 0. 0. 0.\n",
      " 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 2. 1. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1. 2.\n",
      " 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.45\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.27      0.32        11\n",
      "         1.0       0.33      0.50      0.40         8\n",
      "         2.0       0.55      0.52      0.54        21\n",
      "\n",
      "   micro avg       0.45      0.45      0.45        40\n",
      "   macro avg       0.42      0.43      0.42        40\n",
      "weighted avg       0.46      0.45      0.45        40\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 1. 1. 2. 1. 2.\n",
      " 0. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 0. 2. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 2. 2. 0. 2.\n",
      " 2. 2. 2. 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 0. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1.\n",
      " 1. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0. 0. 0. 1.\n",
      " 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 1. 2. 1. 2. 2. 1. 2. 2. 0. 1. 1. 1. 2. 0. 2. 1. 1. 2. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0.]\n",
      "accuracy_train: 0.997275204359673 accuracy_test: 0.575\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      0.99      0.99        78\n",
      "         2.0       0.99      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.36      0.38        11\n",
      "         1.0       0.71      0.62      0.67         8\n",
      "         2.0       0.61      0.67      0.64        21\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        40\n",
      "   macro avg       0.57      0.55      0.56        40\n",
      "weighted avg       0.57      0.57      0.57        40\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 0. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0.\n",
      " 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "[2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 1.\n",
      " 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 0. 1.\n",
      " 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 2. 1. 2. 2. 1. 2. 0. 2. 2. 2. 2. 2. 2. 1. 1. 0. 0. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0. 2. 1. 0.\n",
      " 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 1. 2. 1. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 0. 2. 2. 0. 2. 2. 2. 2. 0. 2. 0. 2. 2. 2.\n",
      " 2. 0. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 1. 1. 1. 2. 0. 2. 0. 1. 1. 2. 1. 1.\n",
      " 2. 0. 2. 0. 0. 1. 0. 2. 0. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.475\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "         2.0       1.00      1.00      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       367\n",
      "   macro avg       1.00      1.00      1.00       367\n",
      "weighted avg       1.00      1.00      1.00       367\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.36      0.33        11\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "         2.0       0.62      0.71      0.67        21\n",
      "\n",
      "   micro avg       0.47      0.47      0.48        40\n",
      "   macro avg       0.31      0.36      0.33        40\n",
      "weighted avg       0.41      0.47      0.44        40\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.42      0.41       111\n",
      "         1.0       0.42      0.41      0.41        86\n",
      "         2.0       0.62      0.61      0.62       210\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.52      0.52      0.52       407\n",
      "\n",
      "0.515970515970516\n",
      "1.2906976744186047\n",
      "<catboost.core.CatBoostClassifier object at 0x7f765803f470>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -1.0983183\ttotal: 7.42s\tremaining: 12m 14s\n",
      "1:\tlearn: -1.0980004\ttotal: 9.34s\tremaining: 7m 37s\n",
      "2:\tlearn: -1.0976774\ttotal: 11.2s\tremaining: 6m 1s\n",
      "3:\tlearn: -1.0973989\ttotal: 13.1s\tremaining: 5m 14s\n",
      "4:\tlearn: -1.0970559\ttotal: 14.9s\tremaining: 4m 43s\n",
      "5:\tlearn: -1.0967485\ttotal: 16.8s\tremaining: 4m 23s\n",
      "6:\tlearn: -1.0964339\ttotal: 18.7s\tremaining: 4m 7s\n",
      "7:\tlearn: -1.0961158\ttotal: 20.5s\tremaining: 3m 56s\n",
      "8:\tlearn: -1.0958088\ttotal: 22.4s\tremaining: 3m 46s\n",
      "9:\tlearn: -1.0955089\ttotal: 24.2s\tremaining: 3m 38s\n",
      "10:\tlearn: -1.0952013\ttotal: 26.1s\tremaining: 3m 30s\n",
      "11:\tlearn: -1.0948872\ttotal: 28s\tremaining: 3m 25s\n",
      "12:\tlearn: -1.0946053\ttotal: 29.9s\tremaining: 3m 20s\n",
      "13:\tlearn: -1.0942784\ttotal: 31.7s\tremaining: 3m 15s\n",
      "14:\tlearn: -1.0939610\ttotal: 33.5s\tremaining: 3m 10s\n",
      "15:\tlearn: -1.0936467\ttotal: 35.4s\tremaining: 3m 5s\n",
      "16:\tlearn: -1.0933216\ttotal: 37.2s\tremaining: 3m 1s\n",
      "17:\tlearn: -1.0930154\ttotal: 39s\tremaining: 2m 57s\n",
      "18:\tlearn: -1.0926861\ttotal: 40.8s\tremaining: 2m 53s\n",
      "19:\tlearn: -1.0923873\ttotal: 42.6s\tremaining: 2m 50s\n",
      "20:\tlearn: -1.0920604\ttotal: 44.5s\tremaining: 2m 47s\n",
      "21:\tlearn: -1.0916503\ttotal: 46.3s\tremaining: 2m 44s\n",
      "22:\tlearn: -1.0913475\ttotal: 48.2s\tremaining: 2m 41s\n",
      "23:\tlearn: -1.0910534\ttotal: 50s\tremaining: 2m 38s\n",
      "24:\tlearn: -1.0907552\ttotal: 51.8s\tremaining: 2m 35s\n",
      "25:\tlearn: -1.0904319\ttotal: 53.7s\tremaining: 2m 32s\n",
      "26:\tlearn: -1.0901280\ttotal: 55.5s\tremaining: 2m 30s\n",
      "27:\tlearn: -1.0898365\ttotal: 57.5s\tremaining: 2m 27s\n",
      "28:\tlearn: -1.0895487\ttotal: 59.3s\tremaining: 2m 25s\n",
      "29:\tlearn: -1.0892293\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "30:\tlearn: -1.0888992\ttotal: 1m 3s\tremaining: 2m 20s\n",
      "31:\tlearn: -1.0885605\ttotal: 1m 5s\tremaining: 2m 18s\n",
      "32:\tlearn: -1.0882170\ttotal: 1m 6s\tremaining: 2m 15s\n",
      "33:\tlearn: -1.0878886\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "34:\tlearn: -1.0875080\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "35:\tlearn: -1.0871734\ttotal: 1m 12s\tremaining: 2m 8s\n",
      "36:\tlearn: -1.0868575\ttotal: 1m 14s\tremaining: 2m 6s\n",
      "37:\tlearn: -1.0865138\ttotal: 1m 16s\tremaining: 2m 4s\n",
      "38:\tlearn: -1.0861953\ttotal: 1m 18s\tremaining: 2m 2s\n",
      "39:\tlearn: -1.0858504\ttotal: 1m 19s\tremaining: 1m 59s\n",
      "40:\tlearn: -1.0854811\ttotal: 1m 21s\tremaining: 1m 57s\n",
      "41:\tlearn: -1.0851557\ttotal: 1m 23s\tremaining: 1m 55s\n",
      "42:\tlearn: -1.0848291\ttotal: 1m 25s\tremaining: 1m 53s\n",
      "43:\tlearn: -1.0844975\ttotal: 1m 27s\tremaining: 1m 51s\n",
      "44:\tlearn: -1.0841539\ttotal: 1m 29s\tremaining: 1m 49s\n",
      "45:\tlearn: -1.0837423\ttotal: 1m 31s\tremaining: 1m 47s\n",
      "46:\tlearn: -1.0833782\ttotal: 1m 32s\tremaining: 1m 44s\n",
      "47:\tlearn: -1.0829771\ttotal: 1m 34s\tremaining: 1m 42s\n",
      "48:\tlearn: -1.0826382\ttotal: 1m 36s\tremaining: 1m 40s\n",
      "49:\tlearn: -1.0822729\ttotal: 1m 38s\tremaining: 1m 38s\n",
      "50:\tlearn: -1.0819336\ttotal: 1m 40s\tremaining: 1m 36s\n",
      "51:\tlearn: -1.0815981\ttotal: 1m 42s\tremaining: 1m 34s\n",
      "52:\tlearn: -1.0812120\ttotal: 1m 44s\tremaining: 1m 32s\n",
      "53:\tlearn: -1.0808809\ttotal: 1m 46s\tremaining: 1m 30s\n",
      "54:\tlearn: -1.0804971\ttotal: 1m 47s\tremaining: 1m 28s\n",
      "55:\tlearn: -1.0801107\ttotal: 1m 49s\tremaining: 1m 26s\n",
      "56:\tlearn: -1.0797685\ttotal: 1m 51s\tremaining: 1m 24s\n",
      "57:\tlearn: -1.0794273\ttotal: 1m 53s\tremaining: 1m 22s\n",
      "58:\tlearn: -1.0790497\ttotal: 1m 55s\tremaining: 1m 20s\n",
      "59:\tlearn: -1.0787108\ttotal: 1m 57s\tremaining: 1m 18s\n",
      "60:\tlearn: -1.0783031\ttotal: 1m 59s\tremaining: 1m 16s\n",
      "61:\tlearn: -1.0779623\ttotal: 2m 1s\tremaining: 1m 14s\n",
      "62:\tlearn: -1.0776167\ttotal: 2m 2s\tremaining: 1m 12s\n",
      "63:\tlearn: -1.0772742\ttotal: 2m 4s\tremaining: 1m 10s\n",
      "64:\tlearn: -1.0768826\ttotal: 2m 6s\tremaining: 1m 8s\n",
      "65:\tlearn: -1.0765117\ttotal: 2m 8s\tremaining: 1m 6s\n"
     ]
    }
   ],
   "source": [
    "models_name=['decision_tree_classifier','gaussian','logistic_regression','MLPClassifier','RandomForestClassifier',\n",
    "             'SVC','Catboost','XGB_classifier','light_gbm','KNeighborsClassifier']\n",
    "for model in models_name:\n",
    "    train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
