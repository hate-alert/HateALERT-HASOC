{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:12:49.977154Z",
     "start_time": "2019-08-07T07:12:49.970149Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:12:50.831372Z",
     "start_time": "2019-08-07T07:12:50.810365Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:12:51.299779Z",
     "start_time": "2019-08-07T07:12:51.287604Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:12:52.687530Z",
     "start_time": "2019-08-07T07:12:52.178097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:13:08.357582Z",
     "start_time": "2019-08-07T07:13:08.295516Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t')\n",
    "# #hindi_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t',header=None)\n",
    "# german_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset_added_features.tsv', sep=',')\n",
    "# eng_train_dataset=eng_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "# german_train_dataset=german_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.loc[eng_train_dataset['task_1'] == 'HOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:13:11.933537Z",
     "start_time": "2019-08-07T07:13:11.905672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5648</td>\n",
       "      <td>सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_164</td>\n",
       "      <td>तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hasoc_hi_6865</td>\n",
       "      <td>#नीच'समानार्थी शब्द #मोदी' दिला तर चालेल की, ल...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hasoc_hi_3763</td>\n",
       "      <td>इस मादरचोद को धुण्डके गांड मे गोली मरो  @Uppolice</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hasoc_hi_5898</td>\n",
       "      <td>You cry in front of ur god  Of being deceived ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text_id                                               text task_1  \\\n",
       "1   hasoc_hi_5648  सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...    HOF   \n",
       "2    hasoc_hi_164  तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...    HOF   \n",
       "18  hasoc_hi_6865  #नीच'समानार्थी शब्द #मोदी' दिला तर चालेल की, ल...    HOF   \n",
       "20  hasoc_hi_3763  इस मादरचोद को धुण्डके गांड मे गोली मरो  @Uppolice    HOF   \n",
       "22  hasoc_hi_5898  You cry in front of ur god  Of being deceived ...    HOF   \n",
       "\n",
       "   task_2 task_3  \n",
       "1    PRFN    UNT  \n",
       "2    PRFN    TIN  \n",
       "18   OFFN    TIN  \n",
       "20   PRFN    UNT  \n",
       "22   PRFN    UNT  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:13:19.109764Z",
     "start_time": "2019-08-07T07:13:19.100281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRFN    1237\n",
      "OFFN     676\n",
      "HATE     556\n",
      "Name: task_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_2'].value_counts()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:13:23.038769Z",
     "start_time": "2019-08-07T07:13:23.018083Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/hindi_dataset/embeddings_eng_task23_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/en_dataset/embeddings_eng_task23_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/english_dataset/no_preprocess_bert_embed_task23.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:13:24.569940Z",
     "start_time": "2019-08-07T07:13:24.564617Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'HATE':0,\n",
    "    'PRFN':1,\n",
    "    'OFFN':2\n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    0:'HATE',\n",
    "    1:'PRFN',\n",
    "    2:'OFFN'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:13:25.590220Z",
     "start_time": "2019-08-07T07:13:25.528823Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_2'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:41:05.526983Z",
     "start_time": "2019-08-07T06:41:04.422373Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 608/2261 [00:00<00:00, 3166.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2261, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2261/2261 [00:00<00:00, 3935.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:41:34.476717Z",
     "start_time": "2019-08-07T06:41:33.797590Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:43:07.015341Z",
     "start_time": "2019-08-07T06:43:07.005345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 2., 2., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:48:46.316858Z",
     "start_time": "2019-08-07T06:48:46.116802Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:48:46.725770Z",
     "start_time": "2019-08-07T06:48:46.702618Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_eng_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['HATE','PRFN','OFFN'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('eng_task2'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('eng_task2'+model_type+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:50:10.309553Z",
     "start_time": "2019-08-07T06:50:10.289747Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3)\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True)\n",
    "    elif m_type == 'KNeighborsClassifier':\n",
    "#         logreg = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "        logreg = neighbors.KNeighborsClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier':\n",
    "        logreg = tree.ExtraTreeClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier_2':\n",
    "        logreg = ensemble.ExtraTreesClassifier()\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,scale_pos_weight=SCALE_POS_WEIGHT)\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=SCALE_POS_WEIGHT,reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='multiclass',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,boosting_type='gbdt',\n",
    "                                metric='multi_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:50:38.819955Z",
     "start_time": "2019-08-07T06:50:11.039639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7136431784107946\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "accuracy_train: 0.9985243482538121 accuracy_test: 0.6754385964912281\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1028\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      1.00      1.00       405\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2033\n",
      "   macro avg       1.00      1.00      1.00      2033\n",
      "weighted avg       1.00      1.00      1.00      2033\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.83      0.76       115\n",
      "         1.0       0.67      0.78      0.72        67\n",
      "         2.0       0.47      0.15      0.23        46\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       228\n",
      "   macro avg       0.61      0.58      0.57       228\n",
      "weighted avg       0.64      0.68      0.64       228\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 1. ... 1. 2. 2.]\n",
      "[0. 1. 1. ... 1. 2. 2.]\n",
      "accuracy_train: 0.9970501474926253 accuracy_test: 0.6255506607929515\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1028\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      0.99      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2034\n",
      "   macro avg       1.00      1.00      1.00      2034\n",
      "weighted avg       1.00      1.00      1.00      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.77      0.72       115\n",
      "         1.0       0.64      0.69      0.66        67\n",
      "         2.0       0.29      0.16      0.20        45\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       227\n",
      "   macro avg       0.54      0.54      0.53       227\n",
      "weighted avg       0.59      0.63      0.60       227\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "accuracy_train: 0.9975417895771878 accuracy_test: 0.7004405286343612\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1028\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      0.99      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2034\n",
      "   macro avg       1.00      1.00      1.00      2034\n",
      "weighted avg       1.00      1.00      1.00      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.85      0.79       115\n",
      "         1.0       0.70      0.78      0.74        67\n",
      "         2.0       0.43      0.20      0.27        45\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       227\n",
      "   macro avg       0.62      0.61      0.60       227\n",
      "weighted avg       0.67      0.70      0.67       227\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "accuracy_train: 0.9970515970515971 accuracy_test: 0.6548672566371682\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      0.99      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.84      0.75       114\n",
      "         1.0       0.67      0.66      0.66        67\n",
      "         2.0       0.44      0.18      0.25        45\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       226\n",
      "   macro avg       0.60      0.56      0.56       226\n",
      "weighted avg       0.63      0.65      0.63       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "accuracy_train: 0.999017199017199 accuracy_test: 0.672566371681416\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      1.00      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.80      0.74       114\n",
      "         1.0       0.73      0.78      0.75        67\n",
      "         2.0       0.39      0.20      0.26        45\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       226\n",
      "   macro avg       0.60      0.59      0.59       226\n",
      "weighted avg       0.64      0.67      0.65       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 1. ... 1. 2. 1.]\n",
      "[0. 0. 1. ... 1. 2. 1.]\n",
      "accuracy_train: 0.9965601965601966 accuracy_test: 0.7389380530973452\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      0.99      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.88      0.81       114\n",
      "         1.0       0.70      0.78      0.74        67\n",
      "         2.0       0.79      0.33      0.47        45\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       226\n",
      "   macro avg       0.75      0.66      0.67       226\n",
      "weighted avg       0.74      0.74      0.72       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "accuracy_train: 0.9970515970515971 accuracy_test: 0.6769911504424779\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      1.00      1.00       600\n",
      "         2.0       1.00      0.99      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.80      0.75       114\n",
      "         1.0       0.65      0.75      0.69        67\n",
      "         2.0       0.57      0.27      0.36        45\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       226\n",
      "   macro avg       0.64      0.60      0.60       226\n",
      "weighted avg       0.66      0.68      0.66       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "[0. 1. 0. ... 2. 2. 1.]\n",
      "accuracy_train: 0.9960707269155207 accuracy_test: 0.6844444444444444\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      1.00      1.00       601\n",
      "         2.0       1.00      1.00      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2036\n",
      "   macro avg       1.00      1.00      1.00      2036\n",
      "weighted avg       1.00      1.00      1.00      2036\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.82      0.75       114\n",
      "         1.0       0.71      0.77      0.74        66\n",
      "         2.0       0.53      0.22      0.31        45\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       225\n",
      "   macro avg       0.64      0.60      0.60       225\n",
      "weighted avg       0.66      0.68      0.66       225\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 1. ... 2. 2. 1.]\n",
      "[1. 0. 1. ... 2. 2. 1.]\n",
      "accuracy_train: 0.9965618860510805 accuracy_test: 0.6933333333333334\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      0.99      1.00       601\n",
      "         2.0       1.00      0.99      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2036\n",
      "   macro avg       1.00      1.00      1.00      2036\n",
      "weighted avg       1.00      1.00      1.00      2036\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.85      0.78       114\n",
      "         1.0       0.70      0.77      0.73        66\n",
      "         2.0       0.47      0.18      0.26        45\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       225\n",
      "   macro avg       0.63      0.60      0.59       225\n",
      "weighted avg       0.66      0.69      0.66       225\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 1. 2. 1.]\n",
      "[0. 1. 0. ... 1. 2. 1.]\n",
      "accuracy_train: 0.9975442043222004 accuracy_test: 0.68\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1029\n",
      "         1.0       1.00      1.00      1.00       601\n",
      "         2.0       1.00      1.00      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2036\n",
      "   macro avg       1.00      1.00      1.00      2036\n",
      "weighted avg       1.00      1.00      1.00      2036\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.76      0.74       114\n",
      "         1.0       0.69      0.83      0.75        66\n",
      "         2.0       0.48      0.24      0.32        45\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       225\n",
      "   macro avg       0.63      0.61      0.60       225\n",
      "weighted avg       0.66      0.68      0.66       225\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.82      0.76      1143\n",
      "         1.0       0.69      0.76      0.72       667\n",
      "         2.0       0.48      0.21      0.29       451\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2261\n",
      "   macro avg       0.62      0.60      0.59      2261\n",
      "weighted avg       0.66      0.68      0.66      2261\n",
      "\n",
      "0.6802299867315347\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,'light_gbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
