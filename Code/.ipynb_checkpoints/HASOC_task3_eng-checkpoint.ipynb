{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:07.753994Z",
     "start_time": "2019-08-07T06:53:06.467573Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:08.560116Z",
     "start_time": "2019-08-07T06:53:08.537617Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:09.562278Z",
     "start_time": "2019-08-07T06:53:09.550159Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:11.637035Z",
     "start_time": "2019-08-07T06:53:11.122673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:16.190339Z",
     "start_time": "2019-08-07T06:53:16.127583Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/english_dataset/english_dataset.tsv', sep='\\t')\n",
    "# #hindi_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t',header=None)\n",
    "# german_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset_added_features.tsv', sep=',')\n",
    "# eng_train_dataset=eng_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "# german_train_dataset=german_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.loc[eng_train_dataset['task_1'] == 'HOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:18.874086Z",
     "start_time": "2019-08-07T06:53:18.846003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_en_2</td>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hasoc_en_8</td>\n",
       "      <td>#ADOS #trendingnow #blacklivesmatter #justice ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hasoc_en_12</td>\n",
       "      <td>I donâ€™t know how much more I can take! 45 is a...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hasoc_en_16</td>\n",
       "      <td>Good work @ICC keep going just destroy the who...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hasoc_en_24</td>\n",
       "      <td>#ShameOnICC  1. ICC on Dhoni's gloves         ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                               text task_1  \\\n",
       "1    hasoc_en_2  @politico No. We should remember very clearly ...    HOF   \n",
       "7    hasoc_en_8  #ADOS #trendingnow #blacklivesmatter #justice ...    HOF   \n",
       "11  hasoc_en_12  I donâ€™t know how much more I can take! 45 is a...    HOF   \n",
       "15  hasoc_en_16  Good work @ICC keep going just destroy the who...    HOF   \n",
       "23  hasoc_en_24  #ShameOnICC  1. ICC on Dhoni's gloves         ...    HOF   \n",
       "\n",
       "   task_2 task_3  \n",
       "1    HATE    TIN  \n",
       "7    PRFN    TIN  \n",
       "11   HATE    TIN  \n",
       "15   PRFN    TIN  \n",
       "23   HATE    TIN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:23.857964Z",
     "start_time": "2019-08-07T06:53:23.848791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIN    2041\n",
      "UNT     220\n",
      "Name: task_3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_3'].value_counts()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:53:31.284634Z",
     "start_time": "2019-08-07T06:53:31.264707Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/english_dataset/embeddings_eng_task23_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/english_dataset/embeddings_eng_task23_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/english_dataset/no_preprocess_bert_embed_task23.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:54:01.219307Z",
     "start_time": "2019-08-07T06:54:01.214285Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'TIN':0,\n",
    "    'UNT':1,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    0:'TIN',\n",
    "    1:'UNT',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:54:08.933810Z",
     "start_time": "2019-08-07T06:54:08.873275Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_3'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:54:10.276556Z",
     "start_time": "2019-08-07T06:54:09.654971Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 372/2261 [00:00<00:00, 3717.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2261, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2261/2261 [00:00<00:00, 3704.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:54:13.875921Z",
     "start_time": "2019-08-07T06:54:13.169628Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:54:14.419549Z",
     "start_time": "2019-08-07T06:54:14.409645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T06:54:20.702150Z",
     "start_time": "2019-08-07T06:54:20.518665Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:50:34.225347Z",
     "start_time": "2019-08-07T07:50:34.194195Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_eng_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['TIN','UNT'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('eng_task3'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('eng_task3'+model_type+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:50:34.661993Z",
     "start_time": "2019-08-07T07:50:34.641438Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3,class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True)\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,\n",
    "            l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,loss_function='MultiClass')\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='multi:softmax',num_class=3,\n",
    "                             reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='multiclass',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,\n",
    "                                boosting_type='gbdt', metric='multi_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T09:39:43.830079Z",
     "start_time": "2019-08-07T09:36:40.164911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.277272727272727\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9149459193706981 accuracy_test: 0.8986784140969163\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95      1836\n",
      "         1.0       0.73      0.20      0.32       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2034\n",
      "   macro avg       0.82      0.60      0.64      2034\n",
      "weighted avg       0.90      0.91      0.89      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.95       205\n",
      "         1.0       0.43      0.14      0.21        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       227\n",
      "   macro avg       0.67      0.56      0.58       227\n",
      "weighted avg       0.87      0.90      0.87       227\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9174447174447175 accuracy_test: 0.8893805309734514\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96      1837\n",
      "         1.0       0.86      0.18      0.30       198\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2035\n",
      "   macro avg       0.89      0.59      0.63      2035\n",
      "weighted avg       0.91      0.92      0.89      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94       204\n",
      "         1.0       0.20      0.05      0.07        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.55      0.51      0.51       226\n",
      "weighted avg       0.84      0.89      0.86       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9105651105651106 accuracy_test: 0.8849557522123894\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95      1837\n",
      "         1.0       0.59      0.27      0.37       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.76      0.62      0.66      2035\n",
      "weighted avg       0.89      0.91      0.90      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.30      0.14      0.19        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.61      0.55      0.56       226\n",
      "weighted avg       0.85      0.88      0.87       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.9154791154791154 accuracy_test: 0.8982300884955752\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.96      1837\n",
      "         1.0       0.96      0.14      0.24       198\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2035\n",
      "   macro avg       0.94      0.57      0.60      2035\n",
      "weighted avg       0.92      0.92      0.89      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95       204\n",
      "         1.0       0.33      0.05      0.08        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.62      0.52      0.51       226\n",
      "weighted avg       0.85      0.90      0.86       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9081081081081082 accuracy_test: 0.8893805309734514\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      1837\n",
      "         1.0       0.92      0.06      0.11       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.92      0.53      0.53      2035\n",
      "weighted avg       0.91      0.91      0.87      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94       204\n",
      "         1.0       0.20      0.05      0.07        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.55      0.51      0.51       226\n",
      "weighted avg       0.84      0.89      0.86       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.917936117936118 accuracy_test: 0.8672566371681416\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96      1837\n",
      "         1.0       0.75      0.23      0.36       198\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2035\n",
      "   macro avg       0.84      0.61      0.66      2035\n",
      "weighted avg       0.91      0.92      0.90      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.96      0.93       204\n",
      "         1.0       0.10      0.05      0.06        22\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       226\n",
      "   macro avg       0.50      0.50      0.50       226\n",
      "weighted avg       0.82      0.87      0.84       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9135135135135135 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      1837\n",
      "         1.0       1.00      0.11      0.20       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.96      0.56      0.58      2035\n",
      "weighted avg       0.92      0.91      0.88      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.99      0.94       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.89      0.85       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9144963144963145 accuracy_test: 0.911504424778761\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.95      1837\n",
      "         1.0       0.82      0.16      0.26       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.87      0.58      0.61      2035\n",
      "weighted avg       0.91      0.91      0.89      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95       204\n",
      "         1.0       0.67      0.18      0.29        22\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       226\n",
      "   macro avg       0.79      0.59      0.62       226\n",
      "weighted avg       0.89      0.91      0.89       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.914004914004914 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95      1837\n",
      "         1.0       0.68      0.22      0.33       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.80      0.61      0.64      2035\n",
      "weighted avg       0.90      0.91      0.89      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94       204\n",
      "         1.0       0.33      0.09      0.14        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.62      0.54      0.54       226\n",
      "weighted avg       0.85      0.89      0.87       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.917936117936118 accuracy_test: 0.8982300884955752\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96      1837\n",
      "         1.0       0.90      0.18      0.30       198\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2035\n",
      "   macro avg       0.91      0.59      0.63      2035\n",
      "weighted avg       0.92      0.92      0.89      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95       204\n",
      "         1.0       0.33      0.05      0.08        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.62      0.52      0.51       226\n",
      "weighted avg       0.85      0.90      0.86       226\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94      2041\n",
      "         1.0       0.30      0.08      0.12       220\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2261\n",
      "   macro avg       0.60      0.53      0.53      2261\n",
      "weighted avg       0.85      0.89      0.86      2261\n",
      "\n",
      "0.8925254312251216\n",
      "9.277272727272727\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8151425762045231 accuracy_test: 0.8061674008810573\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.81      0.89      1836\n",
      "         1.0       0.33      0.84      0.47       198\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2034\n",
      "   macro avg       0.65      0.83      0.68      2034\n",
      "weighted avg       0.92      0.82      0.85      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.82      0.88       205\n",
      "         1.0       0.29      0.68      0.41        22\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       227\n",
      "   macro avg       0.62      0.75      0.64       227\n",
      "weighted avg       0.89      0.81      0.84       227\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.8103194103194103 accuracy_test: 0.7123893805309734\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.81      0.88      1837\n",
      "         1.0       0.32      0.83      0.46       198\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2035\n",
      "   macro avg       0.65      0.82      0.67      2035\n",
      "weighted avg       0.91      0.81      0.84      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.74      0.82       204\n",
      "         1.0       0.17      0.50      0.25        22\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       226\n",
      "   macro avg       0.55      0.62      0.54       226\n",
      "weighted avg       0.86      0.71      0.77       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.8226044226044226 accuracy_test: 0.8097345132743363\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.82      0.89      1837\n",
      "         1.0       0.34      0.84      0.48       198\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2035\n",
      "   macro avg       0.66      0.83      0.69      2035\n",
      "weighted avg       0.92      0.82      0.85      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.85      0.89       204\n",
      "         1.0       0.23      0.41      0.30        22\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       226\n",
      "   macro avg       0.58      0.63      0.59       226\n",
      "weighted avg       0.86      0.81      0.83       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8132678132678133 accuracy_test: 0.7610619469026548\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.81      0.89      1837\n",
      "         1.0       0.32      0.84      0.47       198\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2035\n",
      "   macro avg       0.65      0.83      0.68      2035\n",
      "weighted avg       0.92      0.81      0.85      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86       204\n",
      "         1.0       0.18      0.41      0.25        22\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       226\n",
      "   macro avg       0.55      0.60      0.55       226\n",
      "weighted avg       0.85      0.76      0.80       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8137592137592138 accuracy_test: 0.7477876106194691\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.81      0.89      1837\n",
      "         1.0       0.32      0.84      0.47       198\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2035\n",
      "   macro avg       0.65      0.82      0.68      2035\n",
      "weighted avg       0.92      0.81      0.85      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.75      0.84       204\n",
      "         1.0       0.23      0.68      0.34        22\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       226\n",
      "   macro avg       0.59      0.72      0.59       226\n",
      "weighted avg       0.89      0.75      0.80       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8058968058968059 accuracy_test: 0.7477876106194691\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.80      0.88      1837\n",
      "         1.0       0.32      0.86      0.46       198\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2035\n",
      "   macro avg       0.65      0.83      0.67      2035\n",
      "weighted avg       0.92      0.81      0.84      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.76      0.85       204\n",
      "         1.0       0.21      0.59      0.31        22\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       226\n",
      "   macro avg       0.58      0.68      0.58       226\n",
      "weighted avg       0.87      0.75      0.79       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.7950859950859951 accuracy_test: 0.7212389380530974\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.87      1837\n",
      "         1.0       0.30      0.85      0.45       198\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2035\n",
      "   macro avg       0.64      0.82      0.66      2035\n",
      "weighted avg       0.91      0.80      0.83      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.76      0.83       204\n",
      "         1.0       0.14      0.36      0.20        22\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       226\n",
      "   macro avg       0.53      0.56      0.52       226\n",
      "weighted avg       0.84      0.72      0.77       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8 accuracy_test: 0.7433628318584071\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.80      0.88      1837\n",
      "         1.0       0.31      0.84      0.45       198\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2035\n",
      "   macro avg       0.64      0.82      0.66      2035\n",
      "weighted avg       0.91      0.80      0.84      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.77      0.84       204\n",
      "         1.0       0.18      0.45      0.26        22\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       226\n",
      "   macro avg       0.55      0.61      0.55       226\n",
      "weighted avg       0.86      0.74      0.79       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8098280098280098 accuracy_test: 0.7522123893805309\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.80      0.88      1837\n",
      "         1.0       0.32      0.86      0.47       198\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2035\n",
      "   macro avg       0.65      0.83      0.68      2035\n",
      "weighted avg       0.92      0.81      0.84      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.77      0.85       204\n",
      "         1.0       0.21      0.55      0.30        22\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       226\n",
      "   macro avg       0.57      0.66      0.57       226\n",
      "weighted avg       0.87      0.75      0.80       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8152334152334152 accuracy_test: 0.7787610619469026\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.81      0.89      1837\n",
      "         1.0       0.33      0.86      0.47       198\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2035\n",
      "   macro avg       0.65      0.83      0.68      2035\n",
      "weighted avg       0.92      0.82      0.85      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.79      0.87       204\n",
      "         1.0       0.25      0.64      0.36        22\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       226\n",
      "   macro avg       0.60      0.72      0.61       226\n",
      "weighted avg       0.88      0.78      0.82       226\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.78      0.85      2041\n",
      "         1.0       0.21      0.53      0.30       220\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2261\n",
      "   macro avg       0.57      0.66      0.58      2261\n",
      "weighted avg       0.87      0.76      0.80      2261\n",
      "\n",
      "0.7580716497125166\n",
      "9.277272727272727\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.911504424778761 accuracy_test: 0.801762114537445\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95      1836\n",
      "         1.0       0.52      0.98      0.68       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2034\n",
      "   macro avg       0.76      0.94      0.82      2034\n",
      "weighted avg       0.95      0.91      0.92      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.89       205\n",
      "         1.0       0.19      0.32      0.24        22\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       227\n",
      "   macro avg       0.56      0.59      0.56       227\n",
      "weighted avg       0.85      0.80      0.82       227\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9007371007371008 accuracy_test: 0.8230088495575221\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.49      0.98      0.66       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.75      0.94      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90       204\n",
      "         1.0       0.29      0.55      0.37        22\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       226\n",
      "   macro avg       0.62      0.70      0.64       226\n",
      "weighted avg       0.88      0.82      0.85       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9100737100737101 accuracy_test: 0.7522123893805309\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95      1837\n",
      "         1.0       0.52      0.97      0.68       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.76      0.94      0.81      2035\n",
      "weighted avg       0.95      0.91      0.92      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.85       204\n",
      "         1.0       0.15      0.32      0.20        22\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       226\n",
      "   macro avg       0.53      0.56      0.53       226\n",
      "weighted avg       0.84      0.75      0.79       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.8987714987714988 accuracy_test: 0.8053097345132744\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.49      0.97      0.65       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.74      0.93      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.84      0.89       204\n",
      "         1.0       0.25      0.50      0.33        22\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       226\n",
      "   macro avg       0.59      0.67      0.61       226\n",
      "weighted avg       0.87      0.81      0.83       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9017199017199017 accuracy_test: 0.7831858407079646\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.50      0.97      0.66       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.75      0.93      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.82      0.87       204\n",
      "         1.0       0.21      0.45      0.29        22\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       226\n",
      "   macro avg       0.57      0.64      0.58       226\n",
      "weighted avg       0.86      0.78      0.82       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 1. 0. 1.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9041769041769042 accuracy_test: 0.7964601769911505\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.94      1837\n",
      "         1.0       0.50      0.97      0.66       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.75      0.94      0.80      2035\n",
      "weighted avg       0.95      0.90      0.92      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88       204\n",
      "         1.0       0.24      0.50      0.32        22\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       226\n",
      "   macro avg       0.59      0.66      0.60       226\n",
      "weighted avg       0.87      0.80      0.83       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8992628992628993 accuracy_test: 0.8141592920353983\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.49      0.97      0.65       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.74      0.93      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89       204\n",
      "         1.0       0.25      0.45      0.32        22\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       226\n",
      "   macro avg       0.59      0.65      0.61       226\n",
      "weighted avg       0.87      0.81      0.84       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8987714987714988 accuracy_test: 0.827433628318584\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.49      0.98      0.65       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.74      0.93      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90       204\n",
      "         1.0       0.23      0.32      0.26        22\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       226\n",
      "   macro avg       0.57      0.60      0.58       226\n",
      "weighted avg       0.86      0.83      0.84       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 1. 0. 1.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.8992628992628993 accuracy_test: 0.8362831858407079\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.49      0.97      0.65       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.74      0.93      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91       204\n",
      "         1.0       0.31      0.55      0.39        22\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       226\n",
      "   macro avg       0.63      0.71      0.65       226\n",
      "weighted avg       0.88      0.84      0.86       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.8972972972972973 accuracy_test: 0.7787610619469026\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94      1837\n",
      "         1.0       0.49      0.98      0.65       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.74      0.94      0.80      2035\n",
      "weighted avg       0.95      0.90      0.91      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87       204\n",
      "         1.0       0.13      0.23      0.17        22\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       226\n",
      "   macro avg       0.52      0.53      0.52       226\n",
      "weighted avg       0.83      0.78      0.80       226\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.84      0.88      2041\n",
      "         1.0       0.22      0.42      0.29       220\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2261\n",
      "   macro avg       0.58      0.63      0.59      2261\n",
      "weighted avg       0.86      0.80      0.83      2261\n",
      "\n",
      "0.8018575851393189\n",
      "9.277272727272727\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.9026548672566371 accuracy_test: 0.9030837004405287\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1836\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2034\n",
      "   macro avg       0.45      0.50      0.47      2034\n",
      "weighted avg       0.81      0.90      0.86      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       205\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       227\n",
      "   macro avg       0.45      0.50      0.47       227\n",
      "weighted avg       0.82      0.90      0.86       227\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9090909090909091 accuracy_test: 0.8849557522123894\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95      1837\n",
      "         1.0       0.70      0.12      0.20       198\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2035\n",
      "   macro avg       0.80      0.56      0.58      2035\n",
      "weighted avg       0.89      0.91      0.88      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94       204\n",
      "         1.0       0.17      0.05      0.07        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.54      0.51      0.51       226\n",
      "weighted avg       0.83      0.88      0.85       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9027027027027027 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1837\n",
      "         1.0       0.00      0.00      0.00       198\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2035\n",
      "   macro avg       0.45      0.50      0.47      2035\n",
      "weighted avg       0.81      0.90      0.86      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      2041\n",
      "         1.0       0.17      0.00      0.01       220\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2261\n",
      "   macro avg       0.53      0.50      0.48      2261\n",
      "weighted avg       0.83      0.90      0.86      2261\n",
      "\n",
      "0.9009287925696594\n",
      "9.277272727272727\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9980334316617503 accuracy_test: 0.9074889867841409\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1836\n",
      "         1.0       0.99      0.99      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2034\n",
      "   macro avg       0.99      0.99      0.99      2034\n",
      "weighted avg       1.00      1.00      1.00      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95       205\n",
      "         1.0       1.00      0.05      0.09        22\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       227\n",
      "   macro avg       0.95      0.52      0.52       227\n",
      "weighted avg       0.92      0.91      0.87       227\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.999017199017199 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       0.99      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9985257985257985 accuracy_test: 0.9026548672566371\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      0.99      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      0.99      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.86       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binnym/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.9985257985257985 accuracy_test: 0.9070796460176991\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      0.99      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      0.99      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95       204\n",
      "         1.0       1.00      0.05      0.09        22\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       226\n",
      "   macro avg       0.95      0.52      0.52       226\n",
      "weighted avg       0.92      0.91      0.87       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9985257985257985 accuracy_test: 0.8982300884955752\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       0.99      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95       204\n",
      "         1.0       0.33      0.05      0.08        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.62      0.52      0.51       226\n",
      "weighted avg       0.85      0.90      0.86       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9985257985257985 accuracy_test: 0.911504424778761\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       1.00      0.98      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      0.99      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95       204\n",
      "         1.0       1.00      0.09      0.17        22\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       226\n",
      "   macro avg       0.96      0.55      0.56       226\n",
      "weighted avg       0.92      0.91      0.88       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9985257985257985 accuracy_test: 0.911504424778761\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       0.99      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95       204\n",
      "         1.0       1.00      0.09      0.17        22\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       226\n",
      "   macro avg       0.96      0.55      0.56       226\n",
      "weighted avg       0.92      0.91      0.88       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9985257985257985 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      0.99      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      0.99      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.94       204\n",
      "         1.0       0.25      0.05      0.08        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.58      0.52      0.51       226\n",
      "weighted avg       0.84      0.89      0.86       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.999017199017199 accuracy_test: 0.8982300884955752\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      0.99      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.90      0.85       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9980343980343981 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      0.98      0.99       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      0.99      0.99      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.99      0.94       204\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.45      0.50      0.47       226\n",
      "weighted avg       0.81      0.89      0.85       226\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=7, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=12, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      2041\n",
      "         1.0       0.50      0.04      0.07       220\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2261\n",
      "   macro avg       0.70      0.52      0.51      2261\n",
      "weighted avg       0.87      0.90      0.86      2261\n",
      "\n",
      "0.9026979212737727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.277272727272727\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.960668633235005 accuracy_test: 0.8854625550660793\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1836\n",
      "         1.0       0.97      0.62      0.75       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2034\n",
      "   macro avg       0.96      0.81      0.87      2034\n",
      "weighted avg       0.96      0.96      0.96      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       205\n",
      "         1.0       0.25      0.09      0.13        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       227\n",
      "   macro avg       0.58      0.53      0.54       227\n",
      "weighted avg       0.84      0.89      0.86       227\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9616707616707617 accuracy_test: 0.8805309734513275\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.98      0.62      0.76       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.97      0.81      0.87      2035\n",
      "weighted avg       0.96      0.96      0.96      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94       204\n",
      "         1.0       0.14      0.05      0.07        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.52      0.51      0.50       226\n",
      "weighted avg       0.83      0.88      0.85       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "accuracy_train: 0.9606879606879607 accuracy_test: 0.8893805309734514\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.95      0.63      0.76       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.95      0.81      0.87      2035\n",
      "weighted avg       0.96      0.96      0.96      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94       204\n",
      "         1.0       0.38      0.23      0.29        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.65      0.59      0.61       226\n",
      "weighted avg       0.87      0.89      0.88       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9621621621621622 accuracy_test: 0.8805309734513275\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.98      0.63      0.76       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.97      0.81      0.87      2035\n",
      "weighted avg       0.96      0.96      0.96      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.22      0.09      0.13        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.57      0.53      0.53       226\n",
      "weighted avg       0.84      0.88      0.86       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9582309582309583 accuracy_test: 0.8849557522123894\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.97      0.59      0.73       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.97      0.79      0.85      2035\n",
      "weighted avg       0.96      0.96      0.95      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.25      0.09      0.13        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.58      0.53      0.54       226\n",
      "weighted avg       0.84      0.88      0.86       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9582309582309583 accuracy_test: 0.8849557522123894\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.96      0.60      0.74       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.96      0.80      0.86      2035\n",
      "weighted avg       0.96      0.96      0.95      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.30      0.14      0.19        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.61      0.55      0.56       226\n",
      "weighted avg       0.85      0.88      0.87       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.9601965601965602 accuracy_test: 0.8716814159292036\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.98      0.60      0.75       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.97      0.80      0.86      2035\n",
      "weighted avg       0.96      0.96      0.96      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93       204\n",
      "         1.0       0.29      0.23      0.26        22\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       226\n",
      "   macro avg       0.61      0.58      0.59       226\n",
      "weighted avg       0.86      0.87      0.86       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9587223587223587 accuracy_test: 0.8893805309734514\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.97      0.60      0.74       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.96      0.80      0.86      2035\n",
      "weighted avg       0.96      0.96      0.95      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.33      0.14      0.19        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.62      0.55      0.57       226\n",
      "weighted avg       0.86      0.89      0.87       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9621621621621622 accuracy_test: 0.8672566371681416\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.96      0.64      0.77       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.96      0.82      0.87      2035\n",
      "weighted avg       0.96      0.96      0.96      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       204\n",
      "         1.0       0.21      0.14      0.17        22\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       226\n",
      "   macro avg       0.56      0.54      0.55       226\n",
      "weighted avg       0.84      0.87      0.85       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9601965601965602 accuracy_test: 0.8761061946902655\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      1837\n",
      "         1.0       0.95      0.62      0.75       198\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2035\n",
      "   macro avg       0.96      0.81      0.87      2035\n",
      "weighted avg       0.96      0.96      0.96      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93       204\n",
      "         1.0       0.20      0.09      0.13        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.55      0.53      0.53       226\n",
      "weighted avg       0.84      0.88      0.85       226\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=1526,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94      2041\n",
      "         1.0       0.27      0.13      0.17       220\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      2261\n",
      "   macro avg       0.59      0.54      0.55      2261\n",
      "weighted avg       0.85      0.88      0.86      2261\n",
      "\n",
      "0.8810260946483857\n",
      "9.277272727272727\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9995083579154376 accuracy_test: 0.8942731277533039\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1836\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2034\n",
      "   macro avg       1.00      1.00      1.00      2034\n",
      "weighted avg       1.00      1.00      1.00      2034\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94       205\n",
      "         1.0       0.40      0.18      0.25        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       227\n",
      "   macro avg       0.66      0.58      0.60       227\n",
      "weighted avg       0.87      0.89      0.88       227\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       1.00      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94       204\n",
      "         1.0       0.42      0.23      0.29        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.67      0.60      0.62       226\n",
      "weighted avg       0.87      0.89      0.88       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.8849557522123894\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.30      0.14      0.19        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.61      0.55      0.56       226\n",
      "weighted avg       0.85      0.88      0.87       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 1.0 accuracy_test: 0.8893805309734514\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       1.00      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94       204\n",
      "         1.0       0.38      0.23      0.29        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.65      0.59      0.61       226\n",
      "weighted avg       0.87      0.89      0.88       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.8982300884955752\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.95       204\n",
      "         1.0       0.43      0.14      0.21        22\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       226\n",
      "   macro avg       0.67      0.56      0.58       226\n",
      "weighted avg       0.87      0.90      0.87       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.8716814159292036\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       204\n",
      "         1.0       0.23      0.14      0.17        22\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       226\n",
      "   macro avg       0.57      0.54      0.55       226\n",
      "weighted avg       0.84      0.87      0.86       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.8805309734513275\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.22      0.09      0.13        22\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       226\n",
      "   macro avg       0.57      0.53      0.53       226\n",
      "weighted avg       0.84      0.88      0.86       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 0.]\n",
      "[0. 0. 0. ... 1. 1. 0.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94       204\n",
      "         1.0       0.33      0.09      0.14        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.62      0.54      0.54       226\n",
      "weighted avg       0.85      0.89      0.87       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.9070796460176991\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.98      0.95       204\n",
      "         1.0       0.56      0.23      0.32        22\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       226\n",
      "   macro avg       0.74      0.60      0.64       226\n",
      "weighted avg       0.89      0.91      0.89       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.9995085995085995 accuracy_test: 0.8938053097345132\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1837\n",
      "         1.0       0.99      1.00      1.00       198\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2035\n",
      "   macro avg       1.00      1.00      1.00      2035\n",
      "weighted avg       1.00      1.00      1.00      2035\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94       204\n",
      "         1.0       0.42      0.23      0.29        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       226\n",
      "   macro avg       0.67      0.60      0.62       226\n",
      "weighted avg       0.87      0.89      0.88       226\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=9.277272727272727,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94      2041\n",
      "         1.0       0.37      0.17      0.23       220\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2261\n",
      "   macro avg       0.64      0.57      0.59      2261\n",
      "weighted avg       0.86      0.89      0.87      2261\n",
      "\n",
      "0.8907563025210085\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_name=['decision_tree_classifier','gaussian','logistic_regression','MLPClassifier','RandomForestClassifier',\n",
    "             'SVC','light_gbm']\n",
    "for model in models_name:\n",
    "    train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
