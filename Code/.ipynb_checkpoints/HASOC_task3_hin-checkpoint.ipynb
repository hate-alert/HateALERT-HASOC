{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:15:54.132803Z",
     "start_time": "2019-08-07T07:15:54.126304Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:15:55.328144Z",
     "start_time": "2019-08-07T07:15:55.307203Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:15:56.576662Z",
     "start_time": "2019-08-07T07:15:56.564415Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:15:58.239557Z",
     "start_time": "2019-08-07T07:15:57.823860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:16:25.025958Z",
     "start_time": "2019-08-07T07:16:24.951744Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t')\n",
    "# #hindi_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t',header=None)\n",
    "# german_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset_added_features.tsv', sep=',')\n",
    "# eng_train_dataset=eng_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "# german_train_dataset=german_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.loc[eng_train_dataset['task_1'] == 'HOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:16:27.829029Z",
     "start_time": "2019-08-07T07:16:27.800922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5648</td>\n",
       "      <td>सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_164</td>\n",
       "      <td>तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hasoc_hi_6865</td>\n",
       "      <td>#नीच'समानार्थी शब्द #मोदी' दिला तर चालेल की, ल...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hasoc_hi_3763</td>\n",
       "      <td>इस मादरचोद को धुण्डके गांड मे गोली मरो  @Uppolice</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hasoc_hi_5898</td>\n",
       "      <td>You cry in front of ur god  Of being deceived ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text_id                                               text task_1  \\\n",
       "1   hasoc_hi_5648  सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...    HOF   \n",
       "2    hasoc_hi_164  तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...    HOF   \n",
       "18  hasoc_hi_6865  #नीच'समानार्थी शब्द #मोदी' दिला तर चालेल की, ल...    HOF   \n",
       "20  hasoc_hi_3763  इस मादरचोद को धुण्डके गांड मे गोली मरो  @Uppolice    HOF   \n",
       "22  hasoc_hi_5898  You cry in front of ur god  Of being deceived ...    HOF   \n",
       "\n",
       "   task_2 task_3  \n",
       "1    PRFN    UNT  \n",
       "2    PRFN    TIN  \n",
       "18   OFFN    TIN  \n",
       "20   PRFN    UNT  \n",
       "22   PRFN    UNT  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:16:31.434000Z",
     "start_time": "2019-08-07T07:16:31.424590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIN    1545\n",
      "UNT     924\n",
      "Name: task_3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_3'].value_counts()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:16.273115Z",
     "start_time": "2019-08-07T07:17:16.257735Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/hindi_dataset/embeddings_hin_task23_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/hindi_dataset/embeddings_hin_task23_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/hindi_dataset/no_preprocess_bert_embed_task23.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:17.006829Z",
     "start_time": "2019-08-07T07:17:17.001613Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'TIN':0,\n",
    "    'UNT':1,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    0:'TIN',\n",
    "    1:'UNT',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:17.871727Z",
     "start_time": "2019-08-07T07:17:17.689467Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_3'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:19.458381Z",
     "start_time": "2019-08-07T07:17:18.442092Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 387/2469 [00:00<00:00, 3868.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2469/2469 [00:00<00:00, 4223.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:21.939468Z",
     "start_time": "2019-08-07T07:17:21.226207Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:22.029513Z",
     "start_time": "2019-08-07T07:17:21.942314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:22.984302Z",
     "start_time": "2019-08-07T07:17:22.772401Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:24.275132Z",
     "start_time": "2019-08-07T07:17:24.252110Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_eng_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['TIN','UNT'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('hin_task3'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('hin_task3'+model_type+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:24.978189Z",
     "start_time": "2019-08-07T07:17:24.958266Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3)\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True)\n",
    "    elif m_type == 'KNeighborsClassifier':\n",
    "#         logreg = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "        logreg = neighbors.KNeighborsClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier':\n",
    "        logreg = tree.ExtraTreeClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier_2':\n",
    "        logreg = ensemble.ExtraTreesClassifier()\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,scale_pos_weight=SCALE_POS_WEIGHT)\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=SCALE_POS_WEIGHT,reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='binary',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,boosting_type='gbdt',\n",
    "                                metric='binary_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T07:17:39.551862Z",
     "start_time": "2019-08-07T07:17:25.460250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.672077922077922\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "accuracy_train: 0.989644304367402 accuracy_test: 0.5766129032258065\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      1390\n",
      "         1.0       0.98      1.00      0.99       831\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2221\n",
      "   macro avg       0.99      0.99      0.99      2221\n",
      "weighted avg       0.99      0.99      0.99      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.70      0.67       155\n",
      "         1.0       0.43      0.38      0.40        93\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       248\n",
      "   macro avg       0.54      0.54      0.54       248\n",
      "weighted avg       0.57      0.58      0.57       248\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.990094552003602 accuracy_test: 0.5564516129032258\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      1390\n",
      "         1.0       0.98      1.00      0.99       831\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2221\n",
      "   macro avg       0.99      0.99      0.99      2221\n",
      "weighted avg       0.99      0.99      0.99      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.65      0.65       155\n",
      "         1.0       0.41      0.41      0.41        93\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       248\n",
      "   macro avg       0.53      0.53      0.53       248\n",
      "weighted avg       0.56      0.56      0.56       248\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.9869428185502026 accuracy_test: 0.5846774193548387\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1390\n",
      "         1.0       0.97      1.00      0.98       831\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2221\n",
      "   macro avg       0.98      0.99      0.99      2221\n",
      "weighted avg       0.99      0.99      0.99      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.70      0.68       155\n",
      "         1.0       0.44      0.40      0.42        93\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       248\n",
      "   macro avg       0.55      0.55      0.55       248\n",
      "weighted avg       0.58      0.58      0.58       248\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.9855920756416029 accuracy_test: 0.6048387096774194\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1390\n",
      "         1.0       0.97      1.00      0.98       831\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2221\n",
      "   macro avg       0.98      0.99      0.98      2221\n",
      "weighted avg       0.99      0.99      0.99      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.74      0.70       155\n",
      "         1.0       0.47      0.39      0.42        93\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       248\n",
      "   macro avg       0.57      0.56      0.56       248\n",
      "weighted avg       0.59      0.60      0.60       248\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 1. ... 0. 0. 0.]\n",
      "[1. 0. 1. ... 0. 0. 0.]\n",
      "accuracy_train: 0.9860486048604861 accuracy_test: 0.6072874493927125\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1390\n",
      "         1.0       0.97      1.00      0.98       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2222\n",
      "   macro avg       0.98      0.99      0.99      2222\n",
      "weighted avg       0.99      0.99      0.99      2222\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.72      0.70       155\n",
      "         1.0       0.47      0.42      0.45        92\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       247\n",
      "   macro avg       0.57      0.57      0.57       247\n",
      "weighted avg       0.60      0.61      0.60       247\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.9869545659019343 accuracy_test: 0.6341463414634146\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1391\n",
      "         1.0       0.97      1.00      0.98       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2223\n",
      "   macro avg       0.98      0.99      0.99      2223\n",
      "weighted avg       0.99      0.99      0.99      2223\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.75      0.72       154\n",
      "         1.0       0.51      0.45      0.48        92\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       246\n",
      "   macro avg       0.60      0.60      0.60       246\n",
      "weighted avg       0.63      0.63      0.63       246\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. ... 0. 0. 0.]\n",
      "[1. 0. 1. ... 0. 0. 0.]\n",
      "accuracy_train: 0.9865047233468286 accuracy_test: 0.5650406504065041\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1391\n",
      "         1.0       0.97      1.00      0.98       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2223\n",
      "   macro avg       0.98      0.99      0.99      2223\n",
      "weighted avg       0.99      0.99      0.99      2223\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.69      0.67       154\n",
      "         1.0       0.41      0.35      0.37        92\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       246\n",
      "   macro avg       0.52      0.52      0.52       246\n",
      "weighted avg       0.55      0.57      0.56       246\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.99055330634278 accuracy_test: 0.5934959349593496\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      1391\n",
      "         1.0       0.98      1.00      0.99       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2223\n",
      "   macro avg       0.99      0.99      0.99      2223\n",
      "weighted avg       0.99      0.99      0.99      2223\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.70      0.68       154\n",
      "         1.0       0.45      0.41      0.43        92\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       246\n",
      "   macro avg       0.56      0.56      0.56       246\n",
      "weighted avg       0.59      0.59      0.59       246\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.98740440845704 accuracy_test: 0.5772357723577236\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1391\n",
      "         1.0       0.97      1.00      0.98       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2223\n",
      "   macro avg       0.98      0.99      0.99      2223\n",
      "weighted avg       0.99      0.99      0.99      2223\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.67      0.66       154\n",
      "         1.0       0.43      0.42      0.43        92\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       246\n",
      "   macro avg       0.55      0.55      0.55       246\n",
      "weighted avg       0.58      0.58      0.58       246\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "accuracy_train: 0.9887539361223572 accuracy_test: 0.5609756097560976\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1391\n",
      "         1.0       0.97      1.00      0.99       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2223\n",
      "   macro avg       0.99      0.99      0.99      2223\n",
      "weighted avg       0.99      0.99      0.99      2223\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.64      0.65       154\n",
      "         1.0       0.41      0.42      0.42        92\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       246\n",
      "   macro avg       0.53      0.53      0.53       246\n",
      "weighted avg       0.56      0.56      0.56       246\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.672077922077922,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.69      0.68      1545\n",
      "         1.0       0.44      0.40      0.42       924\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2469\n",
      "   macro avg       0.55      0.55      0.55      2469\n",
      "weighted avg       0.58      0.59      0.58      2469\n",
      "\n",
      "0.5860672336978534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,'light_gbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
