{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:23:32.334361Z",
     "start_time": "2019-08-22T06:23:32.325489Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:12.868834Z",
     "start_time": "2019-08-20T13:45:12.847790Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:13.389918Z",
     "start_time": "2019-08-20T13:45:13.377877Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:14.339000Z",
     "start_time": "2019-08-20T13:45:13.565436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:15.644036Z",
     "start_time": "2019-08-20T13:45:14.341418Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:15.777287Z",
     "start_time": "2019-08-20T13:45:15.647702Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/english_dataset/english_dataset.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:15.824999Z",
     "start_time": "2019-08-20T13:45:15.780091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasoc_en_1</td>\n",
       "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_en_2</td>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_en_3</td>\n",
       "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasoc_en_4</td>\n",
       "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasoc_en_5</td>\n",
       "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_id                                               text task_1  \\\n",
       "0  hasoc_en_1  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   \n",
       "1  hasoc_en_2  @politico No. We should remember very clearly ...    HOF   \n",
       "2  hasoc_en_3  @cricketworldcup Guess who would be the winner...    NOT   \n",
       "3  hasoc_en_4  Corbyn is too politically intellectual for #Bo...    NOT   \n",
       "4  hasoc_en_5  All the best to #TeamIndia for another swimmin...    NOT   \n",
       "\n",
       "  task_2 task_3  \n",
       "0   NONE   NONE  \n",
       "1   HATE    TIN  \n",
       "2   NONE   NONE  \n",
       "3   NONE   NONE  \n",
       "4   NONE   NONE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:16.231855Z",
     "start_time": "2019-08-20T13:45:16.220863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total dataset size: 5852 \n",
      " NOT    3591\n",
      "HOF    2261\n",
      "Name: task_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_1'].value_counts()\n",
    "print(\"the total dataset size:\",len(eng_train_dataset),'\\n',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:16.483446Z",
     "start_time": "2019-08-20T13:45:16.462988Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/english_dataset/embeddings_eng_task1_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/english_dataset/embeddings_eng_task1_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/english_dataset/no_preprocess_bert_embed_task1.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:16.631462Z",
     "start_time": "2019-08-20T13:45:16.626676Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'HOF':1,\n",
    "    'NOT':0\n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    1:'HOF',\n",
    "    0:'NOT'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:17.313451Z",
     "start_time": "2019-08-20T13:45:16.812381Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_1'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:18.610577Z",
     "start_time": "2019-08-20T13:45:17.316288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 962/5852 [00:00<00:00, 4949.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5852, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5852/5852 [00:01<00:00, 4545.82it/s]\n"
     ]
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "#feat_all=merge_feature(engX_lib)\n",
    "\n",
    "\n",
    "# feat_all=[]\n",
    "# for  i in range(len(labels)):\n",
    "#     feat=list(engX_commen[i])+list(engX_lib[i])\n",
    "#     feat_all.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:18.617123Z",
     "start_time": "2019-08-20T13:45:18.612945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:20.303478Z",
     "start_time": "2019-08-20T13:45:18.627484Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:20.422639Z",
     "start_time": "2019-08-20T13:45:20.305918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:20.708362Z",
     "start_time": "2019-08-20T13:45:20.425885Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T15:34:09.864197Z",
     "start_time": "2019-08-06T15:34:09.823545Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:22.123388Z",
     "start_time": "2019-08-20T13:45:22.098002Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_eng_task_1.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "        f1score=f1_score(y_total, y_total_preds, average='macro')\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['NOT','HOF'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('eng_task1'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('eng_task1'+model_type+'_'+report_name,  sep=',')\n",
    "        return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:22.785861Z",
     "start_time": "2019-08-20T13:45:22.767263Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3,class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True,class_weight='balanced')\n",
    "    elif m_type == 'KNeighborsClassifier':\n",
    "#         logreg = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "        logreg = neighbors.KNeighborsClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier':\n",
    "        logreg = tree.ExtraTreeClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier_2':\n",
    "        logreg = ensemble.ExtraTreesClassifier()\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,scale_pos_weight=SCALE_POS_WEIGHT)\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=SCALE_POS_WEIGHT,reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='binary',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,boosting_type='gbdt',\n",
    "                                metric='binary_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:32.314342Z",
     "start_time": "2019-08-20T13:45:23.474122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.588235294117647\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 1. ... 1. 0. 1.]\n",
      "[0. 1. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.576068376068376 accuracy_test: 0.5706984667802385\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.43      0.56      3231\n",
      "         1.0       0.47      0.80      0.59      2034\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      5265\n",
      "   macro avg       0.62      0.62      0.58      5265\n",
      "weighted avg       0.66      0.58      0.57      5265\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.43      0.55       360\n",
      "         1.0       0.47      0.79      0.59       227\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       587\n",
      "   macro avg       0.62      0.61      0.57       587\n",
      "weighted avg       0.65      0.57      0.57       587\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6284412378963357 accuracy_test: 0.5863247863247864\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.64      0.68      3232\n",
      "         1.0       0.52      0.61      0.56      2035\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5267\n",
      "   macro avg       0.62      0.63      0.62      5267\n",
      "weighted avg       0.64      0.63      0.63      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.58      0.63       359\n",
      "         1.0       0.47      0.59      0.53       226\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       585\n",
      "   macro avg       0.58      0.59      0.58       585\n",
      "weighted avg       0.61      0.59      0.59       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6164799696221758 accuracy_test: 0.5914529914529915\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.62      0.66      3232\n",
      "         1.0       0.50      0.62      0.55      2035\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      5267\n",
      "   macro avg       0.61      0.62      0.61      5267\n",
      "weighted avg       0.64      0.62      0.62      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.58      0.64       359\n",
      "         1.0       0.48      0.61      0.53       226\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       585\n",
      "   macro avg       0.59      0.59      0.59       585\n",
      "weighted avg       0.61      0.59      0.60       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-af21a6f8c7c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m              'SVC','light_gbm']\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_model_no_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier_Train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mClassifier_Train_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-57f9981456b6>\u001b[0m in \u001b[0;36mtrain_model_no_ext\u001b[0;34m(Classifier_Train_X, Classifier_Train_Y, model_type, save_model)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_name=['decision_tree_classifier','gaussian','logistic_regression','MLPClassifier','RandomForestClassifier',\n",
    "             'SVC','light_gbm']\n",
    "for model in models_name:\n",
    "    train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T06:13:22.308019Z",
     "start_time": "2019-08-08T06:13:02.046555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.588235294117647\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6442545109211776 accuracy_test: 0.5979557069846678\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.65      0.69      3231\n",
      "         1.0       0.53      0.63      0.58      2034\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5265\n",
      "   macro avg       0.64      0.64      0.64      5265\n",
      "weighted avg       0.66      0.64      0.65      5265\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.59      0.64       360\n",
      "         1.0       0.48      0.62      0.54       227\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       587\n",
      "   macro avg       0.60      0.60      0.59       587\n",
      "weighted avg       0.62      0.60      0.60       587\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6479969622175812 accuracy_test: 0.6170940170940171\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.69      0.71      3232\n",
      "         1.0       0.54      0.58      0.56      2035\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5267\n",
      "   macro avg       0.63      0.64      0.63      5267\n",
      "weighted avg       0.65      0.65      0.65      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.65      0.68       359\n",
      "         1.0       0.50      0.56      0.53       226\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       585\n",
      "   macro avg       0.60      0.61      0.60       585\n",
      "weighted avg       0.63      0.62      0.62       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6174292766280615 accuracy_test: 0.6222222222222222\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.64      0.67      3232\n",
      "         1.0       0.50      0.58      0.54      2035\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      5267\n",
      "   macro avg       0.61      0.61      0.61      5267\n",
      "weighted avg       0.63      0.62      0.62      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.64      0.68       359\n",
      "         1.0       0.51      0.59      0.55       226\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       585\n",
      "   macro avg       0.61      0.62      0.61       585\n",
      "weighted avg       0.64      0.62      0.63       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6654642111258781 accuracy_test: 0.629059829059829\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.80      0.75      3232\n",
      "         1.0       0.59      0.45      0.51      2035\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5267\n",
      "   macro avg       0.64      0.63      0.63      5267\n",
      "weighted avg       0.66      0.67      0.65      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.78      0.72       359\n",
      "         1.0       0.53      0.39      0.45       226\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       585\n",
      "   macro avg       0.60      0.59      0.59       585\n",
      "weighted avg       0.62      0.63      0.62       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.5974938295044617 accuracy_test: 0.5692307692307692\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.50      0.61      3232\n",
      "         1.0       0.49      0.75      0.59      2035\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5267\n",
      "   macro avg       0.62      0.62      0.60      5267\n",
      "weighted avg       0.65      0.60      0.60      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.51      0.59       359\n",
      "         1.0       0.46      0.66      0.54       226\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       585\n",
      "   macro avg       0.58      0.59      0.57       585\n",
      "weighted avg       0.61      0.57      0.57       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 0. ... 1. 0. 0.]\n",
      "[0. 1. 0. ... 0. 1. 1.]\n",
      "accuracy_train: 0.5902790962597304 accuracy_test: 0.5846153846153846\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.51      0.60      3232\n",
      "         1.0       0.48      0.72      0.58      2035\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5267\n",
      "   macro avg       0.61      0.62      0.59      5267\n",
      "weighted avg       0.64      0.59      0.59      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.53      0.61       359\n",
      "         1.0       0.47      0.66      0.55       226\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       585\n",
      "   macro avg       0.59      0.60      0.58       585\n",
      "weighted avg       0.62      0.58      0.59       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 1. ... 0. 0. 1.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6020505031327131 accuracy_test: 0.558974358974359\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.53      0.62      3232\n",
      "         1.0       0.49      0.72      0.58      2035\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5267\n",
      "   macro avg       0.62      0.62      0.60      5267\n",
      "weighted avg       0.65      0.60      0.61      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.50      0.58       359\n",
      "         1.0       0.45      0.65      0.53       226\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       585\n",
      "   macro avg       0.57      0.58      0.56       585\n",
      "weighted avg       0.60      0.56      0.56       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 0. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.5468008353901652 accuracy_test: 0.5264957264957265\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.37      0.50      3232\n",
      "         1.0       0.45      0.82      0.58      2035\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5267\n",
      "   macro avg       0.61      0.60      0.54      5267\n",
      "weighted avg       0.65      0.55      0.53      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.34      0.47       359\n",
      "         1.0       0.44      0.83      0.57       226\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       585\n",
      "   macro avg       0.60      0.58      0.52       585\n",
      "weighted avg       0.63      0.53      0.51       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6584393392823239 accuracy_test: 0.6239316239316239\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.73      0.72      3232\n",
      "         1.0       0.56      0.54      0.55      2035\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5267\n",
      "   macro avg       0.64      0.64      0.64      5267\n",
      "weighted avg       0.66      0.66      0.66      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.69      0.69       359\n",
      "         1.0       0.51      0.53      0.52       226\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       585\n",
      "   macro avg       0.60      0.61      0.61       585\n",
      "weighted avg       0.63      0.62      0.62       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 1. ... 1. 1. 1.]\n",
      "[1. 0. 0. ... 1. 1. 1.]\n",
      "accuracy_train: 0.6048984241503702 accuracy_test: 0.5982905982905983\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.51      0.61      3232\n",
      "         1.0       0.49      0.75      0.60      2035\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5267\n",
      "   macro avg       0.63      0.63      0.60      5267\n",
      "weighted avg       0.66      0.60      0.61      5267\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.50      0.61       359\n",
      "         1.0       0.49      0.75      0.59       226\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       585\n",
      "   macro avg       0.62      0.63      0.60       585\n",
      "weighted avg       0.65      0.60      0.60       585\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.57      0.63      3591\n",
      "         1.0       0.48      0.62      0.54      2261\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5852\n",
      "   macro avg       0.59      0.60      0.59      5852\n",
      "weighted avg       0.62      0.59      0.60      5852\n",
      "\n",
      "0.5927887901572112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5877180059792395"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1score=train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,models_name[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:37:08.440354Z",
     "start_time": "2019-08-22T06:37:05.730694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.588235294117647\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='binary_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='binary', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.588235294117647,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,models_name[-1],save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
