{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:42.966471Z",
     "start_time": "2019-08-22T06:44:42.959395Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:45.434632Z",
     "start_time": "2019-08-22T06:44:45.412093Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:46.869002Z",
     "start_time": "2019-08-22T06:44:46.857490Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:48.616914Z",
     "start_time": "2019-08-22T06:44:48.104848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:52.299868Z",
     "start_time": "2019-08-22T06:44:52.236126Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/english_dataset/english_dataset.tsv', sep='\\t')\n",
    "# #hindi_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t',header=None)\n",
    "# german_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset_added_features.tsv', sep=',')\n",
    "# eng_train_dataset=eng_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "# german_train_dataset=german_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.loc[eng_train_dataset['task_1'] == 'HOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:53.923843Z",
     "start_time": "2019-08-22T06:44:53.895969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_en_2</td>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hasoc_en_8</td>\n",
       "      <td>#ADOS #trendingnow #blacklivesmatter #justice ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hasoc_en_12</td>\n",
       "      <td>I donâ€™t know how much more I can take! 45 is a...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hasoc_en_16</td>\n",
       "      <td>Good work @ICC keep going just destroy the who...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hasoc_en_24</td>\n",
       "      <td>#ShameOnICC  1. ICC on Dhoni's gloves         ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                               text task_1  \\\n",
       "1    hasoc_en_2  @politico No. We should remember very clearly ...    HOF   \n",
       "7    hasoc_en_8  #ADOS #trendingnow #blacklivesmatter #justice ...    HOF   \n",
       "11  hasoc_en_12  I donâ€™t know how much more I can take! 45 is a...    HOF   \n",
       "15  hasoc_en_16  Good work @ICC keep going just destroy the who...    HOF   \n",
       "23  hasoc_en_24  #ShameOnICC  1. ICC on Dhoni's gloves         ...    HOF   \n",
       "\n",
       "   task_2 task_3  \n",
       "1    HATE    TIN  \n",
       "7    PRFN    TIN  \n",
       "11   HATE    TIN  \n",
       "15   PRFN    TIN  \n",
       "23   HATE    TIN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:56.481592Z",
     "start_time": "2019-08-22T06:44:56.472137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HATE    1143\n",
      "PRFN     667\n",
      "OFFN     451\n",
      "Name: task_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_2'].value_counts()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:57.403671Z",
     "start_time": "2019-08-22T06:44:57.383036Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/english_dataset/embeddings_eng_task23_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/english_dataset/embeddings_eng_task23_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/english_dataset/no_preprocess_bert_embed_task23.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:58.174437Z",
     "start_time": "2019-08-22T06:44:58.169093Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'HATE':0,\n",
    "    'PRFN':1,\n",
    "    'OFFN':2\n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    0:'HATE',\n",
    "    1:'PRFN',\n",
    "    2:'OFFN'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:59.249148Z",
     "start_time": "2019-08-22T06:44:58.902727Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_2'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:59.865882Z",
     "start_time": "2019-08-22T06:44:59.286398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 374/2261 [00:00<00:00, 3735.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2261, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2261/2261 [00:00<00:00, 3975.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:01.482807Z",
     "start_time": "2019-08-22T06:45:00.757734Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:01.584054Z",
     "start_time": "2019-08-22T06:45:01.485294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 2., 2., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:01.871090Z",
     "start_time": "2019-08-22T06:45:01.587204Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:05.326754Z",
     "start_time": "2019-08-22T06:45:05.303856Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_eng_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['HATE','PRFN','OFFN'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('eng_task2'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('eng_task2'+model_type+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:07.338874Z",
     "start_time": "2019-08-22T06:45:07.321484Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3,class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True)\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,\n",
    "            l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,loss_function='MultiClass')\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='multi:softmax',num_class=3,\n",
    "                             reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='multiclass',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,\n",
    "                                boosting_type='gbdt', metric='multi_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:22.313705Z",
     "start_time": "2019-08-22T06:45:22.309261Z"
    }
   },
   "outputs": [],
   "source": [
    "models_name=['decision_tree_classifier','gaussian','logistic_regression','MLPClassifier','RandomForestClassifier',\n",
    "             'SVC','light_gbm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:45:19.045400Z",
     "start_time": "2019-08-22T06:45:18.834023Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f342d66f9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_model_no_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier_Train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mClassifier_Train_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models_name' is not defined"
     ]
    }
   ],
   "source": [
    "for model in models_name:\n",
    "    train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-22T06:45:23.779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7136431784107946\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=1.7136431784107946,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,models_name[-1],save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
