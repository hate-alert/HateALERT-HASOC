{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:38.544649Z",
     "start_time": "2019-08-22T06:47:37.259270Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:39.744042Z",
     "start_time": "2019-08-22T06:47:39.722852Z"
    }
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:39.970009Z",
     "start_time": "2019-08-22T06:47:39.957748Z"
    }
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:40.589255Z",
     "start_time": "2019-08-22T06:47:40.134703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....start_cleaning.........\n",
      "hashtag britain exit hashtag rape refugee\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:40.630649Z",
     "start_time": "2019-08-22T06:47:40.591424Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t')\n",
    "# #hindi_train_dataset = pd.read_csv('../Data/hindi_dataset/hindi_dataset.tsv', sep='\\t',header=None)\n",
    "# german_train_dataset = pd.read_csv('../Data/german_dataset/german_dataset_added_features.tsv', sep=',')\n",
    "# eng_train_dataset=eng_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "# german_train_dataset=german_train_dataset.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.loc[eng_train_dataset['task_1'] == 'HOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:40.724355Z",
     "start_time": "2019-08-22T06:47:40.632689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5648</td>\n",
       "      <td>सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_164</td>\n",
       "      <td>तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hasoc_hi_6865</td>\n",
       "      <td>#नीच'समानार्थी शब्द #मोदी' दिला तर चालेल की, ल...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hasoc_hi_3763</td>\n",
       "      <td>इस मादरचोद को धुण्डके गांड मे गोली मरो  @Uppolice</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hasoc_hi_5898</td>\n",
       "      <td>You cry in front of ur god  Of being deceived ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text_id                                               text task_1  \\\n",
       "1   hasoc_hi_5648  सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...    HOF   \n",
       "2    hasoc_hi_164  तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...    HOF   \n",
       "18  hasoc_hi_6865  #नीच'समानार्थी शब्द #मोदी' दिला तर चालेल की, ल...    HOF   \n",
       "20  hasoc_hi_3763  इस मादरचोद को धुण्डके गांड मे गोली मरो  @Uppolice    HOF   \n",
       "22  hasoc_hi_5898  You cry in front of ur god  Of being deceived ...    HOF   \n",
       "\n",
       "   task_2 task_3  \n",
       "1    PRFN    UNT  \n",
       "2    PRFN    TIN  \n",
       "18   OFFN    TIN  \n",
       "20   PRFN    UNT  \n",
       "22   PRFN    UNT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:42.183948Z",
     "start_time": "2019-08-22T06:47:42.174473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRFN    1237\n",
      "OFFN     676\n",
      "HATE     556\n",
      "Name: task_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l=eng_train_dataset['task_2'].value_counts()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:42.402175Z",
     "start_time": "2019-08-22T06:47:42.381829Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "####loading laser embeddings for english dataset\n",
    "def load_laser_embeddings():\n",
    "        dim = 1024\n",
    "        engX_commen = np.fromfile(\"../Data/hindi_dataset/embeddings_hin_task23_commen.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_lib = np.fromfile(\"../Data/hindi_dataset/embeddings_hin_task23_lib.raw\", dtype=np.float32, count=-1)                                                                          \n",
    "        engX_commen.resize(engX_commen.shape[0] // dim, dim)                                                                          \n",
    "        engX_lib.resize(engX_lib.shape[0] // dim, dim)                                                                          \n",
    "        return engX_commen,engX_lib\n",
    "    \n",
    "def load_bert_embeddings():\n",
    "        file = open('../Data/hindi_dataset/no_preprocess_bert_embed_task23.pkl', 'rb')\n",
    "        embeds = pickle.load(file)\n",
    "        return np.array(embeds)\n",
    "        \n",
    "def merge_feature(*args):\n",
    "    feat_all=[]\n",
    "    print(args[0].shape)\n",
    "    for  i in tqdm(range(args[0].shape[0])):\n",
    "        feat=[]\n",
    "        for arg in args:\n",
    "            feat+=list(arg[i])\n",
    "        feat_all.append(feat)\n",
    "    return feat_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:42.552367Z",
     "start_time": "2019-08-22T06:47:42.547205Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_label={\n",
    "    'HATE':0,\n",
    "    'PRFN':1,\n",
    "    'OFFN':2\n",
    "}\n",
    "\n",
    "\n",
    "convert_reverse_label={\n",
    "    0:'HATE',\n",
    "    1:'PRFN',\n",
    "    2:'OFFN'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:43.092191Z",
     "start_time": "2019-08-22T06:47:42.724548Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=eng_train_dataset['task_2'].values\n",
    "engX_commen,engX_lib=load_laser_embeddings()\n",
    "bert_embeds =load_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:43.988337Z",
     "start_time": "2019-08-22T06:47:43.284456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 733/2469 [00:00<00:00, 3641.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2469/2469 [00:00<00:00, 3564.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all=merge_feature(engX_commen,engX_lib,bert_embeds)\n",
    "len(feat_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:44.704730Z",
     "start_time": "2019-08-22T06:47:43.991221Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "Classifier_Train_X=np.array(feat_all)\n",
    "labels_int=[]\n",
    "for i in range(len(labels)):\n",
    "    labels_int.append(convert_label[labels[i]])\n",
    "\n",
    "Classifier_Train_Y=np.array(labels_int,dtype='float64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:44.809647Z",
     "start_time": "2019-08-22T06:47:44.708773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 2., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type_of_target(Classifier_Train_Y))\n",
    "Classifier_Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:45.054682Z",
     "start_time": "2019-08-22T06:47:44.813487Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "\n",
    "###all classifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgbm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:50.154995Z",
     "start_time": "2019-08-22T06:47:50.132414Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model_type,save_model=False):\n",
    "    kf = skf(n_splits=10,shuffle=True)\n",
    "    y_total_preds=[] \n",
    "    y_total=[]\n",
    "    count=0\n",
    "    img_name = 'cm.png'\n",
    "    report_name = 'report.csv'\n",
    "    \n",
    "    scale=list(Classifier_Train_Y).count(0)/list(Classifier_Train_Y).count(1)\n",
    "    print(scale)\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=get_model(scale,m_type=model_type)\n",
    "        Classifier.fit(Classifier_Train_X,Classifier_Train_Y)\n",
    "        filename = model_type+'_hin_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "#         filename1 = model_name+'select_features_eng_task1.joblib.pkl'\n",
    "#         joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "            classifier=get_model(scale,m_type=model_type)\n",
    "            print(type(y_train))\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            print(y_pred_train)\n",
    "            print(y_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['HATE','PRFN','OFFN'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('hin_task2'+model_type+'_'+img_name)\n",
    "        print(classifier)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('hin_task2'+model_type+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:47:51.923425Z",
     "start_time": "2019-08-22T06:47:51.905727Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(scale,m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(max_features=1000,max_depth=3,class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(n_jobs=10, random_state=42,class_weight='balanced',solver='liblinear')\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((100),random_state=42,early_stopping=True)\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=7)\n",
    "    elif m_type == 'SVC':\n",
    "        #logreg = LinearSVC(dual=False,max_iter=200)\n",
    "        logreg = SVC(kernel='linear',random_state=1526)\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(iterations=100,learning_rate=0.2,\n",
    "            l2_leaf_reg=500,depth=10,use_best_model=False, random_state=42,loss_function='MultiClass')\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='multi:softmax',num_class=3,\n",
    "                             reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'light_gbm':\n",
    "        logreg = LGBMClassifier(objective='multiclass',max_depth=3,learning_rate=0.2,num_leaves=20,scale_pos_weight=scale,\n",
    "                                boosting_type='gbdt', metric='multi_logloss',random_state=5,reg_lambda=20,silent=False)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:48:06.625389Z",
     "start_time": "2019-08-22T06:48:06.620336Z"
    }
   },
   "outputs": [],
   "source": [
    "models_name=['decision_tree_classifier','gaussian','logistic_regression','MLPClassifier','RandomForestClassifier',\n",
    "             'SVC','light_gbm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:48:01.674532Z",
     "start_time": "2019-08-22T06:47:53.198683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4494745351657235\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 1. ... 1. 0. 0.]\n",
      "[1. 1. 2. ... 1. 0. 0.]\n",
      "accuracy_train: 0.5542548401620891 accuracy_test: 0.5241935483870968\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.67      0.49       500\n",
      "         1.0       0.68      0.71      0.69      1113\n",
      "         2.0       0.53      0.18      0.26       608\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      2221\n",
      "   macro avg       0.53      0.52      0.48      2221\n",
      "weighted avg       0.57      0.55      0.53      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.43      0.34        56\n",
      "         1.0       0.67      0.73      0.70       124\n",
      "         2.0       0.54      0.22      0.31        68\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       248\n",
      "   macro avg       0.50      0.46      0.45       248\n",
      "weighted avg       0.55      0.52      0.51       248\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 1. 2. ... 2. 2. 2.]\n",
      "[1. 1. 2. ... 1. 0. 0.]\n",
      "accuracy_train: 0.48986942818550205 accuracy_test: 0.4435483870967742\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.49      0.46       500\n",
      "         1.0       0.79      0.46      0.58      1113\n",
      "         2.0       0.33      0.55      0.41       608\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      2221\n",
      "   macro avg       0.52      0.50      0.48      2221\n",
      "weighted avg       0.59      0.49      0.51      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.36      0.36        56\n",
      "         1.0       0.73      0.45      0.56       124\n",
      "         2.0       0.29      0.50      0.37        68\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       248\n",
      "   macro avg       0.46      0.44      0.43       248\n",
      "weighted avg       0.53      0.44      0.46       248\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 2. ... 2. 2. 2.]\n",
      "[1. 1. 2. ... 1. 0. 0.]\n",
      "accuracy_train: 0.514633048176497 accuracy_test: 0.4959677419354839\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.74      0.50       500\n",
      "         1.0       0.76      0.52      0.62      1113\n",
      "         2.0       0.40      0.32      0.36       608\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      2221\n",
      "   macro avg       0.51      0.53      0.49      2221\n",
      "weighted avg       0.58      0.51      0.52      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.75      0.49        56\n",
      "         1.0       0.75      0.47      0.58       124\n",
      "         2.0       0.40      0.34      0.37        68\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       248\n",
      "   macro avg       0.51      0.52      0.48       248\n",
      "weighted avg       0.57      0.50      0.50       248\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 1. 1. ... 1. 2. 0.]\n",
      "[1. 2. 1. ... 1. 0. 0.]\n",
      "accuracy_train: 0.545249887438091 accuracy_test: 0.4879032258064516\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.61      0.49       500\n",
      "         1.0       0.76      0.60      0.67      1113\n",
      "         2.0       0.40      0.39      0.40       608\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      2221\n",
      "   macro avg       0.52      0.53      0.52      2221\n",
      "weighted avg       0.58      0.55      0.55      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.54      0.43        56\n",
      "         1.0       0.74      0.56      0.64       124\n",
      "         2.0       0.30      0.31      0.30        68\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       248\n",
      "   macro avg       0.47      0.47      0.46       248\n",
      "weighted avg       0.53      0.49      0.50       248\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 0. 2. ... 2. 2. 0.]\n",
      "[1. 1. 2. ... 1. 0. 0.]\n",
      "accuracy_train: 0.5646105357946871 accuracy_test: 0.5604838709677419\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.58      0.48       500\n",
      "         1.0       0.72      0.68      0.70      1113\n",
      "         2.0       0.44      0.34      0.39       608\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2221\n",
      "   macro avg       0.53      0.53      0.52      2221\n",
      "weighted avg       0.58      0.56      0.57      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.59      0.50        56\n",
      "         1.0       0.69      0.74      0.72       124\n",
      "         2.0       0.37      0.21      0.26        68\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       248\n",
      "   macro avg       0.50      0.51      0.49       248\n",
      "weighted avg       0.54      0.56      0.54       248\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 2. 1. ... 2. 2. 2.]\n",
      "[1. 1. 2. ... 1. 0. 0.]\n",
      "accuracy_train: 0.5438991445294912 accuracy_test: 0.4435483870967742\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.28      0.37       500\n",
      "         1.0       0.72      0.63      0.67      1113\n",
      "         2.0       0.37      0.61      0.46       608\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      2221\n",
      "   macro avg       0.55      0.50      0.50      2221\n",
      "weighted avg       0.59      0.54      0.55      2221\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.18      0.26        56\n",
      "         1.0       0.58      0.53      0.56       124\n",
      "         2.0       0.30      0.50      0.38        68\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       248\n",
      "   macro avg       0.45      0.40      0.40       248\n",
      "weighted avg       0.48      0.44      0.44       248\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 1. 1. ... 2. 0. 0.]\n",
      "[1. 2. 1. ... 1. 0. 0.]\n",
      "accuracy_train: 0.49122807017543857 accuracy_test: 0.4065040650406504\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.71      0.48       501\n",
      "         1.0       0.80      0.49      0.61      1113\n",
      "         2.0       0.35      0.32      0.33       609\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      2223\n",
      "   macro avg       0.50      0.50      0.47      2223\n",
      "weighted avg       0.57      0.49      0.50      2223\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.56      0.37        55\n",
      "         1.0       0.70      0.44      0.54       124\n",
      "         2.0       0.26      0.22      0.24        67\n",
      "\n",
      "   micro avg       0.41      0.41      0.41       246\n",
      "   macro avg       0.41      0.41      0.38       246\n",
      "weighted avg       0.49      0.41      0.42       246\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 0. 2. ... 1. 0. 0.]\n",
      "[1. 1. 2. ... 1. 0. 0.]\n",
      "accuracy_train: 0.5157374100719424 accuracy_test: 0.4204081632653061\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.78      0.49       501\n",
      "         1.0       0.76      0.59      0.67      1114\n",
      "         2.0       0.37      0.16      0.22       609\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      2224\n",
      "   macro avg       0.50      0.51      0.46      2224\n",
      "weighted avg       0.56      0.52      0.50      2224\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      0.67      0.41        55\n",
      "         1.0       0.68      0.50      0.57       123\n",
      "         2.0       0.17      0.07      0.10        67\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       245\n",
      "   macro avg       0.38      0.41      0.36       245\n",
      "weighted avg       0.45      0.42      0.41       245\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 0. 1. ... 2. 0. 0.]\n",
      "[1. 1. 1. ... 2. 1. 0.]\n",
      "accuracy_train: 0.5350719424460432 accuracy_test: 0.5224489795918368\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.64      0.51       501\n",
      "         1.0       0.73      0.56      0.64      1114\n",
      "         2.0       0.39      0.40      0.40       609\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      2224\n",
      "   macro avg       0.52      0.53      0.51      2224\n",
      "weighted avg       0.57      0.54      0.54      2224\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.60      0.47        55\n",
      "         1.0       0.83      0.53      0.65       123\n",
      "         2.0       0.37      0.45      0.40        67\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       245\n",
      "   macro avg       0.53      0.53      0.51       245\n",
      "weighted avg       0.61      0.52      0.54       245\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "<class 'numpy.ndarray'>\n",
      "[2. 0. 1. ... 1. 0. 2.]\n",
      "[1. 1. 2. ... 0. 2. 0.]\n",
      "accuracy_train: 0.5260791366906474 accuracy_test: 0.4775510204081633\n",
      "TRAINING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.66      0.49       501\n",
      "         1.0       0.76      0.56      0.64      1114\n",
      "         2.0       0.40      0.36      0.38       609\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      2224\n",
      "   macro avg       0.52      0.53      0.50      2224\n",
      "weighted avg       0.58      0.53      0.54      2224\n",
      "\n",
      "TESTING:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.60      0.48        55\n",
      "         1.0       0.67      0.52      0.58       123\n",
      "         2.0       0.30      0.30      0.30        67\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       245\n",
      "   macro avg       0.46      0.47      0.45       245\n",
      "weighted avg       0.51      0.48      0.48       245\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=1000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.53      0.42       556\n",
      "         1.0       0.70      0.55      0.61      1237\n",
      "         2.0       0.32      0.31      0.32       676\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      2469\n",
      "   macro avg       0.46      0.46      0.45      2469\n",
      "weighted avg       0.52      0.48      0.49      2469\n",
      "\n",
      "0.4783313082219522\n",
      "0.4494745351657235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-af21a6f8c7c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m              'SVC','light_gbm']\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_model_no_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier_Train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mClassifier_Train_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-8faf2b1d6ddc>\u001b[0m in \u001b[0;36mtrain_model_no_ext\u001b[0;34m(Classifier_Train_X, Classifier_Train_Y, model_type, save_model)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#         joblib.dump(model_featureSelection, filename1, compress=9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier_Train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mClassifier_Train_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier_Train_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifier_Train_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier_Train_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifier_Train_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HASOC/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_fold_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_cls_splits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mper_cls_cvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_cls_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0mcls_test_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m                 \u001b[0;31m# the test split can be too big because we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0;31m# KFold(...).split(X[:max(c, n_splits)]) when data is not 100%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in models_name:\n",
    "    train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:48:23.834398Z",
     "start_time": "2019-08-22T06:48:20.832723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4494745351657235\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.2, max_depth=3,\n",
      "        metric='multi_logloss', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=20, objective='multiclass', random_state=5,\n",
      "        reg_alpha=0.0, reg_lambda=20, scale_pos_weight=0.4494745351657235,\n",
      "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "train_model_no_ext(Classifier_Train_X,Classifier_Train_Y,models_name[-1],save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HASOC]",
   "language": "python",
   "name": "conda-env-HASOC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
